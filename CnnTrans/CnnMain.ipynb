{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "# from sb3_contrib import RecurrentPPO\n",
    "# from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots\n",
    "# import pandas_ta as ta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "# from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "# import matplotlib.pyplot as plt\n",
    "# from typing import Tuple, Optional\n",
    "import math\n",
    "import mplfinance as mpf\n",
    "from readAndSortCsv import read_and_sort_csv\n",
    "from createSequences import create_sequences\n",
    "from labelSequences import precompute_label_info, get_labels_from_precomputed\n",
    "from plotData import plot_input_output_combined, plot_input_output_combined_with_label\n",
    "from trades import compute_profit, compute_sharpe_ratio\n",
    "from prepareScaledData import scale_X_0_1, encode_labels, compute_sample_profit, get_profitable_indices, get_flat_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'simple1dcnn_state_dict.pth'\n",
    "required_columns = ['date', 'open', 'high', 'low', 'close', 'volume']\n",
    "file_path = r\"E:\\AICore\\Data\\Binance_BTCUSDT_2024_minute.csv\"\n",
    "input_window = 600\n",
    "output_window = 60\n",
    "np.set_printoptions(formatter={'float_kind': lambda x: f'{x:.2f}'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data and compute X, y, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1) Read & sort in descending order\n",
    "# df = read_and_sort_csv(file_path, required_columns)\n",
    "# print(f\"Successfully read {len(df)} rows from the CSV file.\")\n",
    "# print(\"First few rows (descending):\")\n",
    "# print(df.head(3))\n",
    "# print(\"Last few rows (descending):\")\n",
    "# print(df.tail(3))\n",
    "\n",
    "# # 2) Create input/output sequences\n",
    "# X, y = create_sequences(df, input_window=input_window, output_window=output_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # labels = label_sequences(X, y, close_idx=3, volume_idx=4, alpha=0.7, beta=0.3, threshold=1.0)\n",
    "# (\n",
    "#     direction_pct_arr,\n",
    "#     range_diff_arr,\n",
    "#     p_val_arr,\n",
    "#     median_in_arr,\n",
    "#     median_out_arr\n",
    "# ) = precompute_label_info(X, y, close_idx=3, high_idx=1, low_idx=2, volume_idx=4)\n",
    "\n",
    "# labels = get_labels_from_precomputed(\n",
    "#     direction_pct_arr, range_diff_arr, p_val_arr, median_in_arr, median_out_arr,\n",
    "#     alpha=1.469647214304428, beta=0.0054738562416353255, gamma=0, threshold=0.1426995297068393\n",
    "# )\n",
    "# #  {'alpha': 1.469647214304428, 'beta': 0.0054738562416353255, 'threshold': 0.1426995297068393}\n",
    "\n",
    "# print(f\"\\nCreated {X.shape[0]} input-output sequences.\")\n",
    "# print(f\"Input shape: {X.shape}\")\n",
    "# print(f\"Output shape: {y.shape}\")\n",
    "\n",
    "# # 3) (Optional) Scale sequences ...\n",
    "\n",
    "# # 4) (Optional) Save sequences ...\n",
    "\n",
    "# # 5) Plot a sample input-output window on one chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('X.npy', X)\n",
    "# np.save('y.npy', y)\n",
    "# np.save('labels.npy', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load X, y, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('X.npy')\n",
    "y = np.load('y.npy')\n",
    "labels = np.load('labels.npy',allow_pickle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "\n",
    "# # Precompute once\n",
    "# precomp = precompute_label_info(X, y, close_idx=3, high_idx=1, low_idx=2, volume_idx=4)\n",
    "\n",
    "# def objective(trial, objective_name=\"profit\"):\n",
    "#     \"\"\"\n",
    "#     objective_name can be \"profit\" or \"sharpe\" to switch the metric.\n",
    "#     \"\"\"\n",
    "#     # Example: fix alpha = 0, or let it vary\n",
    "#     # alpha = 0\n",
    "#     alpha = trial.suggest_float(\"alpha\", -2.0, 2.0)\n",
    "    \n",
    "#     beta = trial.suggest_float(\"beta\", -1.0, 1.0)\n",
    "#     # gamma = trial.suggest_float(\"gamma\", 0.0, 1.0)\n",
    "#     gamma = 0\n",
    "#     threshold = trial.suggest_float(\"threshold\", 0.0, 1.0)\n",
    "\n",
    "#     # Unpack precomputed\n",
    "#     direction_pct_arr, range_diff_arr, p_val_arr, median_in_arr, median_out_arr = precomp\n",
    "    \n",
    "#     # Get labels quickly\n",
    "#     labels = get_labels_from_precomputed(\n",
    "#         direction_pct_arr, range_diff_arr, p_val_arr, median_in_arr, median_out_arr,\n",
    "#         alpha=alpha, beta=beta, gamma=gamma, threshold=threshold\n",
    "#     )\n",
    "    \n",
    "#     # Evaluate performance\n",
    "#     if objective_name == \"sharpe\":\n",
    "#         score = compute_sharpe_ratio(X, y, labels)\n",
    "#         if score == 0: score = -10\n",
    "#     else:\n",
    "#         score = compute_profit(X, y, labels)\n",
    "    \n",
    "#     # We want to maximize the metric => minimize the negative\n",
    "#     return -score\n",
    "\n",
    "# # Create and run a study, e.g. for profit\n",
    "# study = optuna.create_study(direction=\"minimize\")\n",
    "# study.optimize(lambda t: objective(t, objective_name=\"profit\"), n_trials=500)\n",
    "\n",
    "# print(\"==== Profit Objective ====\")\n",
    "# print(\"Best params:\", study.best_params)\n",
    "# print(\"Max profit found:\", -study.best_value)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If you want a separate run for Sharpe ratio\n",
    "# study_sharpe = optuna.create_study(direction=\"minimize\")\n",
    "# study_sharpe.optimize(lambda t: objective(t, objective_name=\"sharpe\"), n_trials=500)\n",
    "\n",
    "# print(\"==== Sharpe Objective ====\")\n",
    "# print(\"Best params:\", study_sharpe.best_params)\n",
    "# print(\"Max Sharpe found:\", -study_sharpe.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot raw data with lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 4\n",
    "print(labels[sample_idx])\n",
    "# plot_input_output_combined(\n",
    "#     df_original=df,\n",
    "#     start_idx=sample_idx,\n",
    "#     input_window=input_window,\n",
    "#     output_window=output_window,\n",
    "#     title=\"Sample Input & Output on One Chart (start_idx=0)\"\n",
    "# )\n",
    "plot_input_output_combined_with_label(\n",
    "    X[sample_idx],\n",
    "    y[sample_idx],\n",
    "    label=labels[sample_idx],\n",
    "    title=\"Input+Output, Colored by Label\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "dict(zip(unique, counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(labels == 'long'))\n",
    "print(np.where(labels == 'short'))\n",
    "print(np.where(labels == 'flat'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare and scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "oaoao_long = []\n",
    "oaoao_short = []\n",
    "idxs = get_profitable_indices(X, y, labels)\n",
    "profit_lables= labels[idxs]\n",
    "for i, v in enumerate(idxs):\n",
    "    if labels[v] == \"short\":\n",
    "        oaoao_short.append((v))\n",
    "    elif labels[v] == \"long\":\n",
    "        oaoao_long.append((v))\n",
    "flat_idxs = get_flat_indices(labels, 80000)\n",
    "oaoao_flat = random.sample(flat_idxs, 80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(oaoao_long))\n",
    "print(len(oaoao_short))\n",
    "print(len(oaoao_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_idxs = oaoao_long[:80000] + oaoao_short[:80000] + oaoao_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_profit(X[data_idxs], y[data_idxs], labels[data_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data_idxs)\n",
    "zipped_data = list(zip(X[data_idxs], labels[data_idxs], y[data_idxs]))\n",
    "\n",
    "# 3) Slice into train/validate/test\n",
    "#    (These slice boundaries are your choice)\n",
    "train_slice = zipped_data[:192000]\n",
    "val_slice   = zipped_data[192000:-24000]\n",
    "test_slice  = zipped_data[192000 + 24000:]\n",
    "\n",
    "# 4) \"Unzip\" back into separate arrays\n",
    "X_train, y_train, out_train = zip(*train_slice)\n",
    "X_val,   y_val, out_val   = zip(*val_slice)\n",
    "X_test,  y_test, out_test  = zip(*test_slice)\n",
    "\n",
    "# 5) Convert each to np.array\n",
    "X_train, y_train, out_train = np.array(X_train), np.array(y_train), np.array(out_train)\n",
    "X_val,   y_val, out_val    = np.array(X_val),   np.array(y_val), np.array(out_val)\n",
    "X_test,  y_test, out_test  = np.array(X_test),  np.array(y_test), np.array(out_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we have:\n",
    "# X_train, X_val, X_test as (num_samples, input_window, num_features)\n",
    "# y_train, y_val, y_test as string arrays of shape (num_samples,)\n",
    "\n",
    "# 1) Scale X's\n",
    "X_train_scaled, scaler_train = scale_X_0_1(X_train)\n",
    "X_val_scaled = scaler_train.transform(X_val.reshape(-1, X_val.shape[-1])) \\\n",
    "                           .reshape(X_val.shape)\n",
    "X_test_scaled = scaler_train.transform(X_test.reshape(-1, X_test.shape[-1])) \\\n",
    "                            .reshape(X_test.shape)\n",
    "\n",
    "# 2) Encode labels\n",
    "y_train_encoded = encode_labels(y_train)\n",
    "y_val_encoded   = encode_labels(y_val)\n",
    "y_test_encoded  = encode_labels(y_test)\n",
    "\n",
    "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "print(\"y_train_encoded shape:\", y_train_encoded.shape)\n",
    "print(\"Sample encoded labels:\", np.unique(y_train_encoded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Suppose X_train_scaled.shape = (19000, 600, 5)\n",
    "# and y_train_encoded.shape = (19000,)\n",
    "X_train_transposed = np.transpose(X_train_scaled, (0, 2, 1))  # (19000, 5, 600)\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # Convert numpy arrays to PyTorch tensors\n",
    "        self.X = torch.from_numpy(X).float()  # shape: (num_samples, channels, seq_len)\n",
    "        self.y = torch.from_numpy(y).long()   # shape: (num_samples,)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Return (features, label) for sample 'idx'\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = TimeSeriesDataset(X_train_transposed, y_train_encoded)\n",
    "\n",
    "batch_size = 600\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Simple1DCNN(nn.Module):\n",
    "    def __init__(self, num_channels=5, seq_len=600, num_classes=3, dropout_p=0.3):\n",
    "        \"\"\"\n",
    "        An improved 1D CNN for time-series classification.\n",
    "\n",
    "        Args:\n",
    "            num_channels (int): Number of input channels (features). Defaults to 5 (e.g., open/high/low/close/volume).\n",
    "            seq_len (int): Number of timesteps in each sample (e.g., 600).\n",
    "            num_classes (int): Number of output classes (e.g., 3 for 'short','flat','long').\n",
    "            dropout_p (float): Dropout probability for regularization. Defaults to 0.3.\n",
    "        \"\"\"\n",
    "        super(Simple1DCNN, self).__init__()\n",
    "        \n",
    "        # -------------------------\n",
    "        # Convolution Block 1\n",
    "        # -------------------------\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=num_channels, \n",
    "            out_channels=32,\n",
    "            kernel_size=5,         # Larger kernel for broader context\n",
    "            stride=1, \n",
    "            padding=2              # \"same\" padding\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)  # Halves sequence length: 600 -> 300\n",
    "\n",
    "        # -------------------------\n",
    "        # Convolution Block 2\n",
    "        # -------------------------\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=32, \n",
    "            out_channels=64,\n",
    "            kernel_size=5, \n",
    "            stride=1, \n",
    "            padding=2\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)  # 300 -> 150\n",
    "\n",
    "        # -------------------------\n",
    "        # Convolution Block 3\n",
    "        # -------------------------\n",
    "        self.conv3 = nn.Conv1d(\n",
    "            in_channels=64, \n",
    "            out_channels=128,\n",
    "            kernel_size=3, \n",
    "            stride=1, \n",
    "            padding=1\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2)  # 150 -> 75\n",
    "\n",
    "        # After 3 poolings, seq_len -> seq_len / 8\n",
    "        # so final sequence length = 600 / 2 / 2 / 2 = 75\n",
    "        # out channels = 128\n",
    "        # flattened size = 128 * 75 = 9600\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "\n",
    "        self.fc = nn.Linear(128 * (seq_len // 8), num_classes)\n",
    "\n",
    "        # OPTIONAL: If you want to do global average pooling (instead of flattening),\n",
    "        # you can comment out the above fc dimension logic and do:\n",
    "        # self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        # self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x shape: (batch_size, channels=num_channels, seq_len)\n",
    "        \"\"\"\n",
    "        # -------------------------\n",
    "        # Block 1\n",
    "        # -------------------------\n",
    "        x = self.conv1(x)    # (batch, 32, seq_len=600)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)    # (batch, 32, 300)\n",
    "\n",
    "        # -------------------------\n",
    "        # Block 2\n",
    "        # -------------------------\n",
    "        x = self.conv2(x)    # (batch, 64, 300)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)    # (batch, 64, 150)\n",
    "\n",
    "        # -------------------------\n",
    "        # Block 3\n",
    "        # -------------------------\n",
    "        x = self.conv3(x)    # (batch, 128, 150)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)    # (batch, 128, 75)\n",
    "\n",
    "        # -------------------------\n",
    "        # Flatten or Global Pool\n",
    "        # -------------------------\n",
    "        # 1) Flatten approach\n",
    "        x = x.view(x.size(0), -1)  # => (batch, 128 * 75)\n",
    "        \n",
    "        # 2) Dropout for regularization\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # 3) Fully connected output\n",
    "        x = self.fc(x)  # => (batch, num_classes=3)\n",
    "\n",
    "        # OPTIONAL (Global Pooling) approach:\n",
    "        # x = self.global_pool(x)  # => (batch, 128, 1)\n",
    "        # x = x.squeeze(-1)        # => (batch, 128)\n",
    "        # x = self.dropout(x)\n",
    "        # x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = Simple1DCNN(num_channels=5, seq_len=600, num_classes=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the model architecture\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Simple1DCNN(num_channels=5, seq_len=600, num_classes=3)\n",
    "\n",
    "# Load the saved state dictionary\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "\n",
    "# Move to device\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# epoch = 0\n",
    "# while epoch_loss > 0.1:\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "\n",
    "#     for X_batch, y_batch in train_loader:\n",
    "#         X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         outputs = model(X_batch)\n",
    "#         loss = criterion(outputs, y_batch)\n",
    "        \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         running_loss += loss.item() * X_batch.size(0)\n",
    "#         _, pred = torch.max(outputs, 1)\n",
    "#         correct += (pred == y_batch).sum().item()\n",
    "#         total += y_batch.size(0)\n",
    "    \n",
    "#     epoch_loss = running_loss / total\n",
    "#     epoch_acc = correct / total\n",
    "#     print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), MODEL_PATH)\n",
    "# print(f\"Final model saved to {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose X_val_scaled.shape = (val_size, 600, 5)\n",
    "# Suppose y_val_encoded.shape = (val_size,)\n",
    "\n",
    "# 1) Transpose\n",
    "X_val_transposed = np.transpose(X_val_scaled, (0, 2, 1))  # shape: (val_size, 5, 600)\n",
    "\n",
    "# 2) Wrap in a Dataset\n",
    "val_dataset = TimeSeriesDataset(X_val_transposed, y_val_encoded)\n",
    "\n",
    "# 3) Create DataLoader (batch_size can match or differ from train)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# To collect predictions and true labels for further metrics\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in val_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        outputs = model(X_batch)              # shape: (batch_size, num_classes)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        val_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        # Predictions\n",
    "        _, predicted = torch.max(outputs, 1)  # shape: (batch_size,)\n",
    "        \n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "        \n",
    "        # Store predictions & labels for confusion matrix, etc.\n",
    "        all_preds.append(predicted.cpu().numpy())\n",
    "        all_labels.append(y_batch.cpu().numpy())\n",
    "\n",
    "# Convert lists of arrays into a single 1D array\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "val_loss /= total\n",
    "val_acc = correct / total\n",
    "\n",
    "print(f\"Validation Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}\")\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Additional Metrics\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# 1) Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# 2) Classification Report\n",
    "#    If you have 3 classes: 0=\"short\", 1=\"flat\", 2=\"long\" (example)\n",
    "target_names = [\"short\", \"flat\", \"long\"]  # adjust if needed\n",
    "report = classification_report(all_labels, all_preds, target_names=target_names)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose X_test_scaled.shape = (test_size, 600, 5)\n",
    "# Suppose y_test_encoded.shape = (test_size,)\n",
    "\n",
    "# 1) Transpose\n",
    "X_test_transposed = np.transpose(X_test_scaled, (0, 2, 1))  # shape: (test_size, 5, 600)\n",
    "\n",
    "# 2) Wrap in a Dataset\n",
    "test_dataset = TimeSeriesDataset(X_test_transposed, y_test_encoded)\n",
    "\n",
    "# 3) Create DataLoader (batch_size can match or differ from train)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do inference on a single sample from X_test\n",
    "X_single = X_test[-24000]  # shape (600,5) as an example\n",
    "out_single = out_test[-24000]\n",
    "lable_single = y_test[-24000]\n",
    "X_single_scaled = scaler_train.transform(X_single)  # shape (600,5)\n",
    "X_single_scaled = np.expand_dims(X_single_scaled, axis=0)  # => (1,600,5)\n",
    "X_single_transposed = np.transpose(X_single_scaled, (0, 2, 1))  # => (1,5,600)\n",
    "X_single_tensor = torch.from_numpy(X_single_transposed).float().to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(X_single_tensor)   # => shape (1,3)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    predicted_label = predicted.item()  # 0,1,2\n",
    "\n",
    "label_map = {0:\"short\",1:\"flat\",2:\"long\"}\n",
    "print(\"Single sample predicted label:\", label_map[predicted_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do inference on a single sample from X_test\n",
    "predicted_labels = []\n",
    "for X_batch, y_batch  in train_loader:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(X_batch)   # => shape (1,3)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        predicted_label = predicted.item()  # 0,1,2\n",
    "\n",
    "    label_map = {0:\"short\",1:\"flat\",2:\"long\"}\n",
    "    predicted_labels.append(label_map[predicted_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# To collect predictions and true labels for further metrics\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        outputs = model(X_batch)              # shape: (batch_size, num_classes)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        val_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        # Predictions\n",
    "        _, predicted = torch.max(outputs, 1)  # shape: (batch_size,)\n",
    "        \n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "        \n",
    "        # Store predictions & labels for confusion matrix, etc.\n",
    "        all_preds.append(predicted.cpu().numpy())\n",
    "        all_labels.append(y_batch.cpu().numpy())\n",
    "\n",
    "# Convert lists of arrays into a single 1D array\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "val_loss /= total\n",
    "val_acc = correct / total\n",
    "\n",
    "print(f\"Validation Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}\")\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Additional Metrics\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# 1) Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# 2) Classification Report\n",
    "#    If you have 3 classes: 0=\"short\", 1=\"flat\", 2=\"long\" (example)\n",
    "target_names = [\"short\", \"flat\", \"long\"]  # adjust if needed\n",
    "report = classification_report(all_labels, all_preds, target_names=target_names)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kek = labels[data_idxs[:192000]] == predicted_labels\n",
    "unique, counts = np.unique(kek, return_counts=True)\n",
    "\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_profit(X[data_idxs[:192000]], y[data_idxs[:192000]], predicted_labels)\n",
    "# compute_profit(X, y, predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_profit(X[data_idxs[:192000]], y[data_idxs[:192000]], labels[data_idxs[:192000]])\n",
    "# compute_profit(X, y, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_v == labels[data_idxs[-24000:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -23200\n",
    "sample_idx = data_idxs[idx]\n",
    "print(labels[sample_idx])\n",
    "# plot_input_output_combined(\n",
    "#     df_original=df,\n",
    "#     start_idx=sample_idx,\n",
    "#     input_window=input_window,\n",
    "#     output_window=output_window,\n",
    "#     title=\"Sample Input & Output on One Chart (start_idx=0)\"\n",
    "# )\n",
    "plot_input_output_combined_with_label(\n",
    "    X[sample_idx],\n",
    "    y[sample_idx],\n",
    "    label=predicted_labels[idx],\n",
    "    title=\"Input+Output, Colored by Label\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define Label Encoding/Decoding\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit([\"short\", \"flat\", \"long\"])  # Fit with your label classes\n",
    "\n",
    "def encode_labels(y):\n",
    "    return label_encoder.transform(y)\n",
    "\n",
    "def decode_labels(encoded_label):\n",
    "    return label_encoder.inverse_transform([encoded_label])[0]\n",
    "\n",
    "# Inference Function (as defined earlier)\n",
    "def predict_single(model, scaler, input_data, device, encode_fn, decode_fn=None):\n",
    "    model.eval()\n",
    "    input_scaled = scaler.transform(input_data.reshape(-1, input_data.shape[-1])).reshape(input_data.shape)\n",
    "    input_transposed = np.transpose(input_scaled, (1, 0))\n",
    "    input_tensor = torch.from_numpy(input_transposed).float().unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    prediction_encoded = predicted.item()\n",
    "    if decode_fn:\n",
    "        prediction = decode_fn(prediction_encoded)\n",
    "    else:\n",
    "        prediction = prediction_encoded\n",
    "    return prediction\n",
    "\n",
    "def evaluate_new_samples(model, scaler, new_Xs, new_labels, device, encode_fn, decode_fn=None):\n",
    "    results = []\n",
    "    for idx, input_data in enumerate(new_Xs):\n",
    "        prediction = predict_single(model, scaler, input_data, device, encode_fn, decode_fn)\n",
    "        if new_labels:\n",
    "            true_label = new_labels[idx]\n",
    "            correct = (prediction == true_label) if decode_fn else (prediction == encode_fn([true_label])[0])\n",
    "            results.append({\n",
    "                'input_index': idx,\n",
    "                'prediction': prediction,\n",
    "                'true_label': true_label,\n",
    "                'correct': correct\n",
    "            })\n",
    "        else:\n",
    "            results.append({\n",
    "                'input_index': idx,\n",
    "                'prediction': prediction\n",
    "            })\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load or define your trained model\n",
    "# For example:\n",
    "# model = YourModel()\n",
    "# model.load_state_dict(torch.load('model.pth'))\n",
    "# model.to(device)\n",
    "\n",
    "y = np.load('y.npy')\n",
    "# Example new data (replace with your actual data)\n",
    "new_Xs = np.load('X.npy')\n",
    "\n",
    "new_labels = np.load('labels.npy',allow_pickle = True)\n",
    "\n",
    "# Evaluate\n",
    "results = evaluate_new_samples(\n",
    "    model=model,\n",
    "    scaler=scaler_train,\n",
    "    new_Xs=new_Xs,\n",
    "    new_labels=new_labels,\n",
    "    device=device,\n",
    "    encode_fn=encode_labels,\n",
    "    decode_fn=decode_labels\n",
    ")\n",
    "\n",
    "# Display Results\n",
    "for res in results:\n",
    "    print(f\"Sample {res['input_index']}: Prediction = {res['prediction']}, \"\n",
    "            f\"True Label = {res['true_label']}, Correct = {res['correct']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

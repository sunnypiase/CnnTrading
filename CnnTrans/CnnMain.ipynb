{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "# from sb3_contrib import RecurrentPPO\n",
    "# from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots\n",
    "# import pandas_ta as ta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "# from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "# import matplotlib.pyplot as plt\n",
    "# from typing import Tuple, Optional\n",
    "import math\n",
    "import mplfinance as mpf\n",
    "from readAndSortCsv import read_and_sort_csv\n",
    "from createSequences import create_sequences\n",
    "from labelSequences import precompute_label_info, get_labels_from_precomputed\n",
    "from plotData import plot_input_output_combined, plot_input_output_combined_with_label\n",
    "from trades import compute_profit, compute_sharpe_ratio, compute_trading_statistics\n",
    "from prepareScaledData import scale_X_0_1, encode_labels, compute_sample_profit, get_profitable_indices, get_flat_indices\n",
    "from ta import trend, momentum, volatility, volume\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "# import glob\n",
    "\n",
    "# # Define the directory containing the CSV files\n",
    "# csv_directory = r'E:\\AICore\\CnnTrading\\CnnTrans\\Data'  # Change this to your directory path\n",
    "\n",
    "# # Define the required columns\n",
    "# required_columns = ['date', 'open', 'high', 'low', 'close', 'volume']\n",
    "\n",
    "# # Use glob to get all CSV file paths\n",
    "# csv_files = glob.glob(os.path.join(csv_directory, '*.csv'))\n",
    "\n",
    "# # Initialize an empty list to hold individual DataFrames\n",
    "# dataframes = []\n",
    "\n",
    "# # Iterate over each CSV file\n",
    "# for file in csv_files:\n",
    "#     try:\n",
    "#         # Read the CSV file\n",
    "#         df = pd.read_csv(file)\n",
    "#         # print(df.describe())\n",
    "#         # Check if all required columns are present\n",
    "#         if all(column in df.columns for column in required_columns):\n",
    "#             # Select only the required columns\n",
    "#             df = df[required_columns]\n",
    "            \n",
    "#             # Append the DataFrame to the list\n",
    "#             dataframes.append(df)\n",
    "#         else:\n",
    "#             missing = list(set(required_columns) - set(df.columns))\n",
    "#             print(f\"Skipping {file}. Missing columns: {missing}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "# # Concatenate all DataFrames\n",
    "# if dataframes:\n",
    "#     merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "#     # Convert 'date' column to datetime for proper merging\n",
    "#     merged_df['date'] = pd.to_datetime(merged_df['date'])\n",
    "    \n",
    "#     # Drop duplicate dates if necessary (keeping the first occurrence)\n",
    "#     merged_df = merged_df.drop_duplicates(subset=['date'], keep='first')\n",
    "    \n",
    "#     # Sort by date\n",
    "#     merged_df = merged_df.sort_values(by='date', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "#     # Save the merged DataFrame to a new CSV file\n",
    "#     merged_df.to_csv('merged_output.csv', index=False)\n",
    "    \n",
    "#     print(\"CSV files have been successfully merged into 'merged_output.csv'.\")\n",
    "# else:\n",
    "#     print(\"No valid CSV files found to merge.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'simple1dcnn_state_dict.pth'\n",
    "required_columns = ['date', 'open', 'high', 'low', 'close', 'volume']\n",
    "file_path = r\"C:\\GitCnn\\CnnTrading\\CnnTrans\\merged_output.csv\"\n",
    "input_window = 150\n",
    "output_window = 15\n",
    "np.set_printoptions(formatter={'float_kind': lambda x: f'{x:.2f}'})\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data and compute X, y, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Read & sort in descending order\n",
    "df = read_and_sort_csv(file_path, required_columns)\n",
    "\n",
    "# Assuming 'df' is your DataFrame with 'open', 'high', 'low', 'close', 'volume'\n",
    "\n",
    "# Moving Averages\n",
    "df['SMA_20'] = df['close'].rolling(window=20).mean()\n",
    "df['EMA_20'] = df['close'].ewm(span=20, adjust=False).mean()\n",
    "\n",
    "# RSI\n",
    "df['RSI_14'] = momentum.RSIIndicator(close=df['close'], window=14).rsi()\n",
    "\n",
    "# MACD\n",
    "macd = trend.MACD(close=df['close'])\n",
    "df['MACD'] = macd.macd()\n",
    "df['MACD_Signal'] = macd.macd_signal()\n",
    "df['MACD_Diff'] = macd.macd_diff()\n",
    "\n",
    "# Bollinger Bands\n",
    "bollinger = volatility.BollingerBands(close=df['close'], window=20, window_dev=2)\n",
    "df['Bollinger_High'] = bollinger.bollinger_hband()\n",
    "df['Bollinger_Low'] = bollinger.bollinger_lband()\n",
    "df['Bollinger_Middle'] = bollinger.bollinger_mavg()\n",
    "\n",
    "# ATR\n",
    "df['ATR_14'] = volatility.AverageTrueRange(high=df['high'], low=df['low'], close=df['close'], window=14).average_true_range()\n",
    "\n",
    "# OBV\n",
    "df['OBV'] = volume.OnBalanceVolumeIndicator(close=df['close'], volume=df['volume']).on_balance_volume()\n",
    "\n",
    "# Stochastic Oscillator\n",
    "stochastic = momentum.StochasticOscillator(high=df['high'], low=df['low'], close=df['close'], window=14, smooth_window=3)\n",
    "df['Stochastic_%K'] = stochastic.stoch()\n",
    "df['Stochastic_%D'] = stochastic.stoch_signal()\n",
    "\n",
    "# Ichimoku Cloud\n",
    "ichimoku = trend.IchimokuIndicator(high=df['high'], low=df['low'], window1=9, window2=26, window3=52)\n",
    "df['Ichimoku_A'] = ichimoku.ichimoku_a()\n",
    "df['Ichimoku_B'] = ichimoku.ichimoku_b()\n",
    "df['Ichimoku_Base_Line'] = ichimoku.ichimoku_base_line()\n",
    "df['Ichimoku_Conversion_Line'] = ichimoku.ichimoku_conversion_line()\n",
    "\n",
    "# Handle missing values\n",
    "df.dropna(inplace=True)  # or df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_Signal</th>\n",
       "      <th>...</th>\n",
       "      <th>Bollinger_Low</th>\n",
       "      <th>Bollinger_Middle</th>\n",
       "      <th>ATR_14</th>\n",
       "      <th>OBV</th>\n",
       "      <th>Stochastic_%K</th>\n",
       "      <th>Stochastic_%D</th>\n",
       "      <th>Ichimoku_A</th>\n",
       "      <th>Ichimoku_B</th>\n",
       "      <th>Ichimoku_Base_Line</th>\n",
       "      <th>Ichimoku_Conversion_Line</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:34:00</th>\n",
       "      <td>7176.24</td>\n",
       "      <td>7176.24</td>\n",
       "      <td>7175.42</td>\n",
       "      <td>7175.77</td>\n",
       "      <td>3.14500</td>\n",
       "      <td>7174.7275</td>\n",
       "      <td>7175.689302</td>\n",
       "      <td>49.533929</td>\n",
       "      <td>-0.389558</td>\n",
       "      <td>-0.882934</td>\n",
       "      <td>...</td>\n",
       "      <td>7170.600666</td>\n",
       "      <td>7174.7275</td>\n",
       "      <td>3.238610</td>\n",
       "      <td>-290.216000</td>\n",
       "      <td>57.990868</td>\n",
       "      <td>69.748858</td>\n",
       "      <td>7177.3050</td>\n",
       "      <td>7179.395</td>\n",
       "      <td>7179.395</td>\n",
       "      <td>7175.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:35:00</th>\n",
       "      <td>7175.76</td>\n",
       "      <td>7175.76</td>\n",
       "      <td>7174.14</td>\n",
       "      <td>7174.14</td>\n",
       "      <td>26.80800</td>\n",
       "      <td>7174.5215</td>\n",
       "      <td>7175.541749</td>\n",
       "      <td>46.253894</td>\n",
       "      <td>-0.473266</td>\n",
       "      <td>-0.801000</td>\n",
       "      <td>...</td>\n",
       "      <td>7170.722246</td>\n",
       "      <td>7174.5215</td>\n",
       "      <td>3.123709</td>\n",
       "      <td>-317.024000</td>\n",
       "      <td>39.383562</td>\n",
       "      <td>53.652968</td>\n",
       "      <td>7177.3050</td>\n",
       "      <td>7179.395</td>\n",
       "      <td>7179.395</td>\n",
       "      <td>7175.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:36:00</th>\n",
       "      <td>7174.66</td>\n",
       "      <td>7175.71</td>\n",
       "      <td>7174.66</td>\n",
       "      <td>7175.71</td>\n",
       "      <td>8.45000</td>\n",
       "      <td>7174.5305</td>\n",
       "      <td>7175.557773</td>\n",
       "      <td>49.708266</td>\n",
       "      <td>-0.408214</td>\n",
       "      <td>-0.722443</td>\n",
       "      <td>...</td>\n",
       "      <td>7170.720894</td>\n",
       "      <td>7174.5305</td>\n",
       "      <td>3.012730</td>\n",
       "      <td>-308.574000</td>\n",
       "      <td>57.305936</td>\n",
       "      <td>51.560122</td>\n",
       "      <td>7176.8800</td>\n",
       "      <td>7179.395</td>\n",
       "      <td>7178.060</td>\n",
       "      <td>7175.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:37:00</th>\n",
       "      <td>7175.71</td>\n",
       "      <td>7175.92</td>\n",
       "      <td>7174.69</td>\n",
       "      <td>7175.76</td>\n",
       "      <td>14.27500</td>\n",
       "      <td>7174.6080</td>\n",
       "      <td>7175.577033</td>\n",
       "      <td>49.818882</td>\n",
       "      <td>-0.348606</td>\n",
       "      <td>-0.647676</td>\n",
       "      <td>...</td>\n",
       "      <td>7170.764712</td>\n",
       "      <td>7174.6080</td>\n",
       "      <td>2.885392</td>\n",
       "      <td>-294.299000</td>\n",
       "      <td>57.876712</td>\n",
       "      <td>51.522070</td>\n",
       "      <td>7176.4900</td>\n",
       "      <td>7179.395</td>\n",
       "      <td>7177.175</td>\n",
       "      <td>7175.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:38:00</th>\n",
       "      <td>7175.76</td>\n",
       "      <td>7176.37</td>\n",
       "      <td>7175.76</td>\n",
       "      <td>7176.37</td>\n",
       "      <td>2.77500</td>\n",
       "      <td>7174.7835</td>\n",
       "      <td>7175.652553</td>\n",
       "      <td>51.228279</td>\n",
       "      <td>-0.249271</td>\n",
       "      <td>-0.567995</td>\n",
       "      <td>...</td>\n",
       "      <td>7170.954990</td>\n",
       "      <td>7174.7835</td>\n",
       "      <td>2.722864</td>\n",
       "      <td>-291.524000</td>\n",
       "      <td>63.636364</td>\n",
       "      <td>59.606337</td>\n",
       "      <td>7176.2750</td>\n",
       "      <td>7179.395</td>\n",
       "      <td>7176.430</td>\n",
       "      <td>7176.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-26 23:55:00</th>\n",
       "      <td>95856.71</td>\n",
       "      <td>95856.71</td>\n",
       "      <td>95828.24</td>\n",
       "      <td>95828.25</td>\n",
       "      <td>2.59874</td>\n",
       "      <td>95790.5420</td>\n",
       "      <td>95781.792308</td>\n",
       "      <td>56.434153</td>\n",
       "      <td>30.676563</td>\n",
       "      <td>31.702057</td>\n",
       "      <td>...</td>\n",
       "      <td>95714.629499</td>\n",
       "      <td>95790.5420</td>\n",
       "      <td>49.493024</td>\n",
       "      <td>-537451.095175</td>\n",
       "      <td>75.907898</td>\n",
       "      <td>71.993177</td>\n",
       "      <td>95738.0000</td>\n",
       "      <td>95614.515</td>\n",
       "      <td>95678.355</td>\n",
       "      <td>95797.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-26 23:56:00</th>\n",
       "      <td>95828.25</td>\n",
       "      <td>95839.06</td>\n",
       "      <td>95820.73</td>\n",
       "      <td>95838.58</td>\n",
       "      <td>2.68533</td>\n",
       "      <td>95794.8700</td>\n",
       "      <td>95787.200660</td>\n",
       "      <td>57.362873</td>\n",
       "      <td>31.496596</td>\n",
       "      <td>31.660965</td>\n",
       "      <td>...</td>\n",
       "      <td>95718.368219</td>\n",
       "      <td>95794.8700</td>\n",
       "      <td>47.267093</td>\n",
       "      <td>-537448.409845</td>\n",
       "      <td>84.652501</td>\n",
       "      <td>86.850645</td>\n",
       "      <td>95738.0000</td>\n",
       "      <td>95614.515</td>\n",
       "      <td>95678.355</td>\n",
       "      <td>95797.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-26 23:57:00</th>\n",
       "      <td>95838.59</td>\n",
       "      <td>95838.59</td>\n",
       "      <td>95829.07</td>\n",
       "      <td>95829.07</td>\n",
       "      <td>4.81558</td>\n",
       "      <td>95802.3090</td>\n",
       "      <td>95791.188216</td>\n",
       "      <td>56.175598</td>\n",
       "      <td>31.021504</td>\n",
       "      <td>31.533073</td>\n",
       "      <td>...</td>\n",
       "      <td>95745.393446</td>\n",
       "      <td>95802.3090</td>\n",
       "      <td>44.570872</td>\n",
       "      <td>-537453.225425</td>\n",
       "      <td>76.602049</td>\n",
       "      <td>79.054149</td>\n",
       "      <td>95745.9975</td>\n",
       "      <td>95614.515</td>\n",
       "      <td>95694.350</td>\n",
       "      <td>95797.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-26 23:58:00</th>\n",
       "      <td>95829.08</td>\n",
       "      <td>95829.08</td>\n",
       "      <td>95808.10</td>\n",
       "      <td>95808.11</td>\n",
       "      <td>11.27959</td>\n",
       "      <td>95803.9900</td>\n",
       "      <td>95792.799815</td>\n",
       "      <td>53.545113</td>\n",
       "      <td>28.623737</td>\n",
       "      <td>30.951205</td>\n",
       "      <td>...</td>\n",
       "      <td>95748.491998</td>\n",
       "      <td>95803.9900</td>\n",
       "      <td>42.885810</td>\n",
       "      <td>-537464.505015</td>\n",
       "      <td>58.858884</td>\n",
       "      <td>73.371145</td>\n",
       "      <td>95752.1025</td>\n",
       "      <td>95614.515</td>\n",
       "      <td>95706.560</td>\n",
       "      <td>95797.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-26 23:59:00</th>\n",
       "      <td>95808.10</td>\n",
       "      <td>95808.55</td>\n",
       "      <td>95791.60</td>\n",
       "      <td>95791.60</td>\n",
       "      <td>1.94588</td>\n",
       "      <td>95803.9510</td>\n",
       "      <td>95792.685547</td>\n",
       "      <td>51.499463</td>\n",
       "      <td>25.101910</td>\n",
       "      <td>29.781346</td>\n",
       "      <td>...</td>\n",
       "      <td>95748.419332</td>\n",
       "      <td>95803.9510</td>\n",
       "      <td>41.033252</td>\n",
       "      <td>-537466.450895</td>\n",
       "      <td>44.882756</td>\n",
       "      <td>60.114563</td>\n",
       "      <td>95769.4375</td>\n",
       "      <td>95614.515</td>\n",
       "      <td>95741.230</td>\n",
       "      <td>95797.645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2621738 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open      high       low     close    volume  \\\n",
       "date                                                                    \n",
       "2020-01-01 00:34:00   7176.24   7176.24   7175.42   7175.77   3.14500   \n",
       "2020-01-01 00:35:00   7175.76   7175.76   7174.14   7174.14  26.80800   \n",
       "2020-01-01 00:36:00   7174.66   7175.71   7174.66   7175.71   8.45000   \n",
       "2020-01-01 00:37:00   7175.71   7175.92   7174.69   7175.76  14.27500   \n",
       "2020-01-01 00:38:00   7175.76   7176.37   7175.76   7176.37   2.77500   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2024-12-26 23:55:00  95856.71  95856.71  95828.24  95828.25   2.59874   \n",
       "2024-12-26 23:56:00  95828.25  95839.06  95820.73  95838.58   2.68533   \n",
       "2024-12-26 23:57:00  95838.59  95838.59  95829.07  95829.07   4.81558   \n",
       "2024-12-26 23:58:00  95829.08  95829.08  95808.10  95808.11  11.27959   \n",
       "2024-12-26 23:59:00  95808.10  95808.55  95791.60  95791.60   1.94588   \n",
       "\n",
       "                         SMA_20        EMA_20     RSI_14       MACD  \\\n",
       "date                                                                  \n",
       "2020-01-01 00:34:00   7174.7275   7175.689302  49.533929  -0.389558   \n",
       "2020-01-01 00:35:00   7174.5215   7175.541749  46.253894  -0.473266   \n",
       "2020-01-01 00:36:00   7174.5305   7175.557773  49.708266  -0.408214   \n",
       "2020-01-01 00:37:00   7174.6080   7175.577033  49.818882  -0.348606   \n",
       "2020-01-01 00:38:00   7174.7835   7175.652553  51.228279  -0.249271   \n",
       "...                         ...           ...        ...        ...   \n",
       "2024-12-26 23:55:00  95790.5420  95781.792308  56.434153  30.676563   \n",
       "2024-12-26 23:56:00  95794.8700  95787.200660  57.362873  31.496596   \n",
       "2024-12-26 23:57:00  95802.3090  95791.188216  56.175598  31.021504   \n",
       "2024-12-26 23:58:00  95803.9900  95792.799815  53.545113  28.623737   \n",
       "2024-12-26 23:59:00  95803.9510  95792.685547  51.499463  25.101910   \n",
       "\n",
       "                     MACD_Signal  ...  Bollinger_Low  Bollinger_Middle  \\\n",
       "date                              ...                                    \n",
       "2020-01-01 00:34:00    -0.882934  ...    7170.600666         7174.7275   \n",
       "2020-01-01 00:35:00    -0.801000  ...    7170.722246         7174.5215   \n",
       "2020-01-01 00:36:00    -0.722443  ...    7170.720894         7174.5305   \n",
       "2020-01-01 00:37:00    -0.647676  ...    7170.764712         7174.6080   \n",
       "2020-01-01 00:38:00    -0.567995  ...    7170.954990         7174.7835   \n",
       "...                          ...  ...            ...               ...   \n",
       "2024-12-26 23:55:00    31.702057  ...   95714.629499        95790.5420   \n",
       "2024-12-26 23:56:00    31.660965  ...   95718.368219        95794.8700   \n",
       "2024-12-26 23:57:00    31.533073  ...   95745.393446        95802.3090   \n",
       "2024-12-26 23:58:00    30.951205  ...   95748.491998        95803.9900   \n",
       "2024-12-26 23:59:00    29.781346  ...   95748.419332        95803.9510   \n",
       "\n",
       "                        ATR_14            OBV  Stochastic_%K  Stochastic_%D  \\\n",
       "date                                                                          \n",
       "2020-01-01 00:34:00   3.238610    -290.216000      57.990868      69.748858   \n",
       "2020-01-01 00:35:00   3.123709    -317.024000      39.383562      53.652968   \n",
       "2020-01-01 00:36:00   3.012730    -308.574000      57.305936      51.560122   \n",
       "2020-01-01 00:37:00   2.885392    -294.299000      57.876712      51.522070   \n",
       "2020-01-01 00:38:00   2.722864    -291.524000      63.636364      59.606337   \n",
       "...                        ...            ...            ...            ...   \n",
       "2024-12-26 23:55:00  49.493024 -537451.095175      75.907898      71.993177   \n",
       "2024-12-26 23:56:00  47.267093 -537448.409845      84.652501      86.850645   \n",
       "2024-12-26 23:57:00  44.570872 -537453.225425      76.602049      79.054149   \n",
       "2024-12-26 23:58:00  42.885810 -537464.505015      58.858884      73.371145   \n",
       "2024-12-26 23:59:00  41.033252 -537466.450895      44.882756      60.114563   \n",
       "\n",
       "                     Ichimoku_A  Ichimoku_B  Ichimoku_Base_Line  \\\n",
       "date                                                              \n",
       "2020-01-01 00:34:00   7177.3050    7179.395            7179.395   \n",
       "2020-01-01 00:35:00   7177.3050    7179.395            7179.395   \n",
       "2020-01-01 00:36:00   7176.8800    7179.395            7178.060   \n",
       "2020-01-01 00:37:00   7176.4900    7179.395            7177.175   \n",
       "2020-01-01 00:38:00   7176.2750    7179.395            7176.430   \n",
       "...                         ...         ...                 ...   \n",
       "2024-12-26 23:55:00  95738.0000   95614.515           95678.355   \n",
       "2024-12-26 23:56:00  95738.0000   95614.515           95678.355   \n",
       "2024-12-26 23:57:00  95745.9975   95614.515           95694.350   \n",
       "2024-12-26 23:58:00  95752.1025   95614.515           95706.560   \n",
       "2024-12-26 23:59:00  95769.4375   95614.515           95741.230   \n",
       "\n",
       "                     Ichimoku_Conversion_Line  \n",
       "date                                           \n",
       "2020-01-01 00:34:00                  7175.215  \n",
       "2020-01-01 00:35:00                  7175.215  \n",
       "2020-01-01 00:36:00                  7175.700  \n",
       "2020-01-01 00:37:00                  7175.805  \n",
       "2020-01-01 00:38:00                  7176.120  \n",
       "...                                       ...  \n",
       "2024-12-26 23:55:00                 95797.645  \n",
       "2024-12-26 23:56:00                 95797.645  \n",
       "2024-12-26 23:57:00                 95797.645  \n",
       "2024-12-26 23:58:00                 95797.645  \n",
       "2024-12-26 23:59:00                 95797.645  \n",
       "\n",
       "[2621738 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read 2621738 rows from the CSV file.\n",
      "First few rows (asc):\n",
      "                        open     high      low    close  volume     SMA_20  \\\n",
      "date                                                                         \n",
      "2020-01-01 00:34:00  7176.24  7176.24  7175.42  7175.77   3.145  7174.7275   \n",
      "2020-01-01 00:35:00  7175.76  7175.76  7174.14  7174.14  26.808  7174.5215   \n",
      "2020-01-01 00:36:00  7174.66  7175.71  7174.66  7175.71   8.450  7174.5305   \n",
      "\n",
      "                          EMA_20     RSI_14      MACD  MACD_Signal  ...  \\\n",
      "date                                                                ...   \n",
      "2020-01-01 00:34:00  7175.689302  49.533929 -0.389558    -0.882934  ...   \n",
      "2020-01-01 00:35:00  7175.541749  46.253894 -0.473266    -0.801000  ...   \n",
      "2020-01-01 00:36:00  7175.557773  49.708266 -0.408214    -0.722443  ...   \n",
      "\n",
      "                     Bollinger_Low  Bollinger_Middle    ATR_14      OBV  \\\n",
      "date                                                                      \n",
      "2020-01-01 00:34:00    7170.600666         7174.7275  3.238610 -290.216   \n",
      "2020-01-01 00:35:00    7170.722246         7174.5215  3.123709 -317.024   \n",
      "2020-01-01 00:36:00    7170.720894         7174.5305  3.012730 -308.574   \n",
      "\n",
      "                     Stochastic_%K  Stochastic_%D  Ichimoku_A  Ichimoku_B  \\\n",
      "date                                                                        \n",
      "2020-01-01 00:34:00      57.990868      69.748858    7177.305    7179.395   \n",
      "2020-01-01 00:35:00      39.383562      53.652968    7177.305    7179.395   \n",
      "2020-01-01 00:36:00      57.305936      51.560122    7176.880    7179.395   \n",
      "\n",
      "                     Ichimoku_Base_Line  Ichimoku_Conversion_Line  \n",
      "date                                                               \n",
      "2020-01-01 00:34:00            7179.395                  7175.215  \n",
      "2020-01-01 00:35:00            7179.395                  7175.215  \n",
      "2020-01-01 00:36:00            7178.060                  7175.700  \n",
      "\n",
      "[3 rows x 22 columns]\n",
      "Last few rows (asc):\n",
      "                         open      high       low     close    volume  \\\n",
      "date                                                                    \n",
      "2024-12-26 23:57:00  95838.59  95838.59  95829.07  95829.07   4.81558   \n",
      "2024-12-26 23:58:00  95829.08  95829.08  95808.10  95808.11  11.27959   \n",
      "2024-12-26 23:59:00  95808.10  95808.55  95791.60  95791.60   1.94588   \n",
      "\n",
      "                        SMA_20        EMA_20     RSI_14       MACD  \\\n",
      "date                                                                 \n",
      "2024-12-26 23:57:00  95802.309  95791.188216  56.175598  31.021504   \n",
      "2024-12-26 23:58:00  95803.990  95792.799815  53.545113  28.623737   \n",
      "2024-12-26 23:59:00  95803.951  95792.685547  51.499463  25.101910   \n",
      "\n",
      "                     MACD_Signal  ...  Bollinger_Low  Bollinger_Middle  \\\n",
      "date                              ...                                    \n",
      "2024-12-26 23:57:00    31.533073  ...   95745.393446         95802.309   \n",
      "2024-12-26 23:58:00    30.951205  ...   95748.491998         95803.990   \n",
      "2024-12-26 23:59:00    29.781346  ...   95748.419332         95803.951   \n",
      "\n",
      "                        ATR_14            OBV  Stochastic_%K  Stochastic_%D  \\\n",
      "date                                                                          \n",
      "2024-12-26 23:57:00  44.570872 -537453.225425      76.602049      79.054149   \n",
      "2024-12-26 23:58:00  42.885810 -537464.505015      58.858884      73.371145   \n",
      "2024-12-26 23:59:00  41.033252 -537466.450895      44.882756      60.114563   \n",
      "\n",
      "                     Ichimoku_A  Ichimoku_B  Ichimoku_Base_Line  \\\n",
      "date                                                              \n",
      "2024-12-26 23:57:00  95745.9975   95614.515            95694.35   \n",
      "2024-12-26 23:58:00  95752.1025   95614.515            95706.56   \n",
      "2024-12-26 23:59:00  95769.4375   95614.515            95741.23   \n",
      "\n",
      "                     Ichimoku_Conversion_Line  \n",
      "date                                           \n",
      "2024-12-26 23:57:00                 95797.645  \n",
      "2024-12-26 23:58:00                 95797.645  \n",
      "2024-12-26 23:59:00                 95797.645  \n",
      "\n",
      "[3 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Successfully read {len(df)} rows from the CSV file.\")\n",
    "print(\"First few rows (asc):\")\n",
    "print(df.head(3))\n",
    "print(\"Last few rows (asc):\")\n",
    "print(df.tail(3))\n",
    "\n",
    "# 2) Create input/output sequences\n",
    "# data = list(zip(*create_sequences(df, input_window=input_window, output_window=output_window, step=150)))\n",
    "# np.random.shuffle(data)\n",
    "# X, y = zip(*data)\n",
    "# X, y = np.array(X), np.array(y)\n",
    "# del data\n",
    "X, y = create_sequences(df, input_window=input_window, output_window=output_window, step=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17478, 150, 22)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_labels_simple(\n",
    "    X: np.ndarray, \n",
    "    y: np.ndarray, \n",
    "    close_idx: int = 3, \n",
    "    threshold: float = 0.03\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes labels based on the percentage difference between the last\n",
    "    closing price of the input and output windows.\n",
    "\n",
    "    Args:\n",
    "        X: Input window data, shape (num_samples, input_window, num_features).\n",
    "        y: Output window data, shape (num_samples, output_window, num_features).\n",
    "        close_idx: Index of the closing price in the feature set.\n",
    "        threshold: Percentage threshold to classify \"long\" or \"short\".\n",
    "\n",
    "    Returns:\n",
    "        labels: An array of labels (\"long\", \"short\", \"flat\"), shape (num_samples,).\n",
    "    \"\"\"\n",
    "    num_samples = X.shape[0]\n",
    "    labels = np.empty(num_samples, dtype=object)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        price_in_end = X[i, -1, close_idx]\n",
    "        price_out_end = y[i, -1, close_idx]\n",
    "\n",
    "        if price_in_end == 0:\n",
    "            labels[i] = \"flat\"  # Avoid division by zero\n",
    "            continue\n",
    "\n",
    "        pct_diff = ((price_out_end - price_in_end) / price_in_end) * 100\n",
    "\n",
    "        if pct_diff > threshold:\n",
    "            labels[i] = \"long\"\n",
    "        elif pct_diff < -threshold:\n",
    "            labels[i] = \"short\"\n",
    "        else:\n",
    "            labels[i] = \"flat\"\n",
    "\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 17478 input-output sequences.\n",
      "Input shape: (17478, 150, 22)\n",
      "Output shape: (17478, 15, 22)\n"
     ]
    }
   ],
   "source": [
    "# # labels = label_sequences(X, y, close_idx=3, volume_idx=4, alpha=0.7, beta=0.3, threshold=1.0)\n",
    "# (\n",
    "#     direction_pct_arr,\n",
    "#     range_diff_arr,\n",
    "#     p_val_arr,\n",
    "#     median_in_arr,\n",
    "#     median_out_arr\n",
    "# ) = precompute_label_info(X, y, close_idx=3, high_idx=1, low_idx=2, volume_idx=4)\n",
    "\n",
    "# labels = get_labels_from_precomputed(\n",
    "#     direction_pct_arr, range_diff_arr, p_val_arr, median_in_arr, median_out_arr,\n",
    "#     alpha=1.469647214304428, beta=0.0054738562416353255, gamma=0, threshold=0.1426995297068393\n",
    "# )\n",
    "# #  {'alpha': 1.469647214304428, 'beta': 0.0054738562416353255, 'threshold': 0.1426995297068393}\n",
    "labels = compute_labels_simple(X, y, threshold = 0.15)\n",
    "print(f\"\\nCreated {X.shape[0]} input-output sequences.\")\n",
    "print(f\"Input shape: {X.shape}\")\n",
    "print(f\"Output shape: {y.shape}\")\n",
    "\n",
    "# 3) (Optional) Scale sequences ...\n",
    "\n",
    "# 4) (Optional) Save sequences ...\n",
    "\n",
    "# 5) Plot a sample input-output window on one chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('X.npy', X)\n",
    "# np.save('y.npy', y)\n",
    "# np.save('labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load X, y, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Splitting:\n",
      "X_train_slice shape: (13982, 150, 22)\n",
      "y_train_slice shape: (13982, 15, 22)\n",
      "labels_train_slice shape: (13982,)\n",
      "\n",
      "X_val_slice shape: (1747, 150, 22)\n",
      "y_val_slice shape: (1747, 15, 22)\n",
      "labels_val_slice shape: (1747,)\n",
      "\n",
      "X_test_slice shape: (1749, 150, 22)\n",
      "y_test_slice shape: (1749, 15, 22)\n",
      "labels_test_slice shape: (1749,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_percent = 0.8    # 80% for training\n",
    "val_percent = 0.1      # 10% for validation\n",
    "test_percent = 0.1     # 10% for testing\n",
    "\n",
    "# Ensure that the percentages sum to 1\n",
    "assert train_percent + val_percent + test_percent == 1.0, \"Percentages must sum to 1.\"\n",
    "\n",
    "# Calculate the number of samples\n",
    "total_samples = len(X)\n",
    "train_end = int(train_percent * total_samples)\n",
    "val_end = train_end + int(val_percent * total_samples)\n",
    "\n",
    "# Split the data\n",
    "X_train_slice = X[:train_end]\n",
    "y_train_slice = y[:train_end]\n",
    "labels_train_slice = labels[:train_end]\n",
    "\n",
    "X_val_slice = X[train_end:val_end]\n",
    "y_val_slice = y[train_end:val_end]\n",
    "labels_val_slice = labels[train_end:val_end]\n",
    "\n",
    "X_test_slice = X[val_end:]\n",
    "y_test_slice = y[val_end:]\n",
    "labels_test_slice = labels[val_end:]\n",
    "\n",
    "print(\"After Splitting:\")\n",
    "print(f\"X_train_slice shape: {X_train_slice.shape}\")\n",
    "print(f\"y_train_slice shape: {y_train_slice.shape}\")\n",
    "print(f\"labels_train_slice shape: {labels_train_slice.shape}\\n\")\n",
    "\n",
    "print(f\"X_val_slice shape: {X_val_slice.shape}\")\n",
    "print(f\"y_val_slice shape: {y_val_slice.shape}\")\n",
    "print(f\"labels_val_slice shape: {labels_val_slice.shape}\\n\")\n",
    "\n",
    "print(f\"X_test_slice shape: {X_test_slice.shape}\")\n",
    "print(f\"y_test_slice shape: {y_test_slice.shape}\")\n",
    "print(f\"labels_test_slice shape: {labels_test_slice.shape}\\n\")\n",
    "\n",
    "# Save the slices to disk\n",
    "# np.save('X_train_slice.npy', X_train_slice)\n",
    "# np.save('y_train_slice.npy', y_train_slice)\n",
    "# np.save('labels_train_slice.npy', labels_train_slice)\n",
    "\n",
    "# np.save('X_val_slice.npy', X_val_slice)\n",
    "# np.save('y_val_slice.npy', y_val_slice)\n",
    "# np.save('labels_val_slice.npy', labels_val_slice)\n",
    "\n",
    "# np.save('X_test_slice.npy', X_test_slice)\n",
    "# np.save('y_test_slice.npy', y_test_slice)\n",
    "# np.save('labels_test_slice.npy', labels_test_slice)\n",
    "\n",
    "# print(\"Data slices have been saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the slices from disk\n",
    "# X_train_slice = np.load('X_train_slice.npy')\n",
    "# y_train_slice = np.load('y_train_slice.npy')\n",
    "# labels_train_slice = np.load('labels_train_slice.npy')\n",
    "\n",
    "# X_val_slice = np.load('X_val_slice.npy')\n",
    "# y_val_slice = np.load('y_val_slice.npy')\n",
    "# labels_val_slice = np.load('labels_val_slice.npy')\n",
    "\n",
    "# X_test_slice = np.load('X_test_slice.npy')\n",
    "# y_test_slice = np.load('y_test_slice.npy')\n",
    "# labels_test_slice = np.load('labels_test_slice.npy')\n",
    "\n",
    "# print(\"Data slices have been loaded successfully.\")\n",
    "# # Print shapes after loading\n",
    "# print(\"After Loading:\")\n",
    "# print(f\"X_train_loaded shape: {X_train_slice.shape}\")\n",
    "# print(f\"y_train_loaded shape: {y_train_slice.shape}\")\n",
    "# print(f\"labels_train_loaded shape: {labels_train_slice.shape}\\n\")\n",
    "\n",
    "# print(f\"X_val_loaded shape: {X_val_slice.shape}\")\n",
    "# print(f\"y_val_loaded shape: {y_val_slice.shape}\")\n",
    "# print(f\"labels_val_loaded shape: {labels_val_slice.shape}\\n\")\n",
    "\n",
    "# print(f\"X_test_loaded shape: {X_test_slice.shape}\")\n",
    "# print(f\"y_test_loaded shape: {y_test_slice.shape}\")\n",
    "# print(f\"labels_test_loaded shape: {labels_test_slice.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X\n",
    "del y\n",
    "del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13982\n",
      "1747\n",
      "1749\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_slice))\n",
    "print(len(X_val_slice))\n",
    "print(len(X_test_slice))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "\n",
    "# # Precompute once\n",
    "# precomp = precompute_label_info(X, y, close_idx=3, high_idx=1, low_idx=2, volume_idx=4)\n",
    "\n",
    "# def objective(trial, objective_name=\"profit\"):\n",
    "#     \"\"\"\n",
    "#     objective_name can be \"profit\" or \"sharpe\" to switch the metric.\n",
    "#     \"\"\"\n",
    "#     # Example: fix alpha = 0, or let it vary\n",
    "#     # alpha = 0\n",
    "#     alpha = trial.suggest_float(\"alpha\", -2.0, 2.0)\n",
    "    \n",
    "#     beta = trial.suggest_float(\"beta\", -1.0, 1.0)\n",
    "#     # gamma = trial.suggest_float(\"gamma\", 0.0, 1.0)\n",
    "#     gamma = 0\n",
    "#     threshold = trial.suggest_float(\"threshold\", 0.0, 1.0)\n",
    "\n",
    "#     # Unpack precomputed\n",
    "#     direction_pct_arr, range_diff_arr, p_val_arr, median_in_arr, median_out_arr = precomp\n",
    "    \n",
    "#     # Get labels quickly\n",
    "#     labels = get_labels_from_precomputed(\n",
    "#         direction_pct_arr, range_diff_arr, p_val_arr, median_in_arr, median_out_arr,\n",
    "#         alpha=alpha, beta=beta, gamma=gamma, threshold=threshold\n",
    "#     )\n",
    "    \n",
    "#     # Evaluate performance\n",
    "#     if objective_name == \"sharpe\":\n",
    "#         score = compute_sharpe_ratio(X, y, labels)\n",
    "#         if score == 0: score = -10\n",
    "#     else:\n",
    "#         score = compute_profit(X, y, labels)\n",
    "    \n",
    "#     # We want to maximize the metric => minimize the negative\n",
    "#     return -score\n",
    "\n",
    "# # Create and run a study, e.g. for profit\n",
    "# study = optuna.create_study(direction=\"minimize\")\n",
    "# study.optimize(lambda t: objective(t, objective_name=\"profit\"), n_trials=500)\n",
    "\n",
    "# print(\"==== Profit Objective ====\")\n",
    "# print(\"Best params:\", study.best_params)\n",
    "# print(\"Max profit found:\", -study.best_value)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If you want a separate run for Sharpe ratio\n",
    "# study_sharpe = optuna.create_study(direction=\"minimize\")\n",
    "# study_sharpe.optimize(lambda t: objective(t, objective_name=\"sharpe\"), n_trials=500)\n",
    "\n",
    "# print(\"==== Sharpe Objective ====\")\n",
    "# print(\"Best params:\", study_sharpe.best_params)\n",
    "# print(\"Max Sharpe found:\", -study_sharpe.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot raw data with lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_idx = 4\n",
    "# print(labels[sample_idx])\n",
    "# # plot_input_output_combined(\n",
    "# #     df_original=df,\n",
    "# #     start_idx=sample_idx,\n",
    "# #     input_window=input_window,\n",
    "# #     output_window=output_window,\n",
    "# #     title=\"Sample Input & Output on One Chart (start_idx=0)\"\n",
    "# # )\n",
    "# plot_input_output_combined_with_label(\n",
    "#     X[sample_idx],\n",
    "#     y[sample_idx],\n",
    "#     label=labels[sample_idx],\n",
    "#     title=\"Input+Output, Colored by Label\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniqueLabels(labelsToUnique):\n",
    "    unique, counts = np.unique(labelsToUnique, return_counts=True)\n",
    "\n",
    "    print(dict(zip(unique, counts)))\n",
    "\n",
    "    print(len(np.where(labelsToUnique == 'long')[0]))\n",
    "    print(len(np.where(labelsToUnique == 'short')[0]))\n",
    "    print(len(np.where(labelsToUnique == 'flat')[0]))\n",
    "    return counts.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flat': np.int64(7590), 'long': np.int64(3169), 'short': np.int64(3223)}\n",
      "3169\n",
      "3223\n",
      "7590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(3169)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_train = uniqueLabels(labels_train_slice)\n",
    "min_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flat': np.int64(1019), 'long': np.int64(388), 'short': np.int64(340)}\n",
      "388\n",
      "340\n",
      "1019\n"
     ]
    }
   ],
   "source": [
    "min_labels = uniqueLabels(labels_val_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flat': np.int64(1033), 'long': np.int64(356), 'short': np.int64(360)}\n",
      "356\n",
      "360\n",
      "1033\n"
     ]
    }
   ],
   "source": [
    "min_test = uniqueLabels(labels_test_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare and scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indexs_for_slice(x_input, y_input, labels_input, min_input):\n",
    "    oaoao_long = []\n",
    "    oaoao_short = []\n",
    "    idxs = get_profitable_indices(x_input, y_input, labels_input)\n",
    "    for i, v in enumerate(idxs):\n",
    "        if labels_input[v] == \"short\":\n",
    "            oaoao_short.append((v))\n",
    "        elif labels_input[v] == \"long\":\n",
    "            oaoao_long.append((v))\n",
    "    minLen = min(len(oaoao_long), len(oaoao_short), min_input)\n",
    "    print(\"minlem\", minLen)\n",
    "    flat_idxs = get_flat_indices(labels_input, minLen)\n",
    "    oaoao_flat = random.sample(flat_idxs, minLen)\n",
    "    print(len(oaoao_long))\n",
    "    print(len(oaoao_short))\n",
    "    print(len(oaoao_flat))\n",
    "    return oaoao_long[:minLen] + oaoao_short[:minLen] + oaoao_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minlem 3169\n",
      "3169\n",
      "3223\n",
      "3169\n",
      "minlem 340\n",
      "388\n",
      "340\n",
      "340\n",
      "minlem 356\n",
      "356\n",
      "360\n",
      "356\n"
     ]
    }
   ],
   "source": [
    "train_idxs = get_indexs_for_slice(X_train_slice, y_train_slice, labels_train_slice, min_train)\n",
    "val_idxs = get_indexs_for_slice(X_val_slice, y_val_slice, labels_val_slice, min_labels)\n",
    "test_idxs = get_indexs_for_slice(X_test_slice, y_test_slice, labels_test_slice, min_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(62.26503767029209)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_profit(X_val_slice, y_val_slice, labels_val_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13982, 150, 22)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.shuffle(range(len(X_train_slice)))\n",
    "# np.random.shuffle(val_idxs)\n",
    "# np.random.shuffle(test_idxs)\n",
    "\n",
    "# 5) Convert each to np.array\n",
    "X_train, y_train, out_train = np.array(X_train_slice[train_idxs]), np.array(labels_train_slice[train_idxs]), np.array(y_train_slice[train_idxs])\n",
    "X_val,   y_val, out_val    = np.array(X_val_slice[val_idxs]),   np.array(labels_val_slice[val_idxs]), np.array(y_val_slice[val_idxs])\n",
    "X_test,  y_test, out_test  = np.array(X_test_slice[test_idxs]),  np.array(labels_test_slice[test_idxs]), np.array(y_test_slice[test_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9507, 150, 22)\n",
      "(1020, 150, 22)\n",
      "(1068, 150, 22)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "def scale_X_0_1_per_sequence(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Scales each feature (across the time steps) within each sequence of the 3D array X independently to [0, 1].\n",
    "    A new MinMaxScaler instance is applied for each feature in each sequence.\n",
    "\n",
    "    Args:\n",
    "        X: 3D numpy array of shape (num_samples, input_window, num_features).\n",
    "\n",
    "    Returns:\n",
    "        X_scaled: Scaled version of X, where each feature is independently scaled within each sequence.\n",
    "    \"\"\"\n",
    "    num_samples, input_window, num_features = X.shape\n",
    "\n",
    "    # Initialize an array to store scaled data\n",
    "    X_scaled = np.zeros_like(X)\n",
    "\n",
    "    for sample_idx in range(num_samples):\n",
    "        for feature_idx in range(num_features):\n",
    "            # Extract the time series for a single feature in a single sequence\n",
    "            feature_sequence = X[sample_idx, :, feature_idx].reshape(-1, 1)\n",
    "            \n",
    "            # Create a MinMaxScaler for this specific sequence\n",
    "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            \n",
    "            # Fit and transform the feature sequence\n",
    "            scaled_sequence = scaler.fit_transform(feature_sequence)\n",
    "            \n",
    "            # Assign the scaled sequence back to the corresponding location\n",
    "            X_scaled[sample_idx, :, feature_idx] = scaled_sequence.flatten()\n",
    "\n",
    "    return X_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_gaussian_noise(X, noise_factor=0.05):\n",
    "    \"\"\"\n",
    "    Adds Gaussian noise to the input data.\n",
    "\n",
    "    Parameters:\n",
    "    - X: numpy array, shape (num_samples, input_window, num_features)\n",
    "    - noise_factor: float, standard deviation of the Gaussian noise\n",
    "\n",
    "    Returns:\n",
    "    - X_noisy: numpy array with added Gaussian noise, same shape as X\n",
    "    \"\"\"\n",
    "    # Generate Gaussian noise\n",
    "    noise = np.random.normal(loc=0.0, scale=noise_factor, size=X.shape)\n",
    "    \n",
    "    # Add noise to the original data\n",
    "    X_noisy = X + noise\n",
    "    \n",
    "    # Clip the values to ensure they remain within [0, 1]\n",
    "    X_noisy = np.clip(X_noisy, 0.0, 1.0)\n",
    "    \n",
    "    return X_noisy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (9507, 150, 22)\n",
      "y_train_encoded shape: (9507,)\n",
      "Sample encoded labels: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Suppose we have:\n",
    "# X_train, X_val, X_test as (num_samples, input_window, num_features)\n",
    "# y_train, y_val, y_test as string arrays of shape (num_samples,)\n",
    "\n",
    "# 1) Scale X's\n",
    "\n",
    "X_train_scaled = scale_X_0_1_per_sequence(X_train)\n",
    "# X_train_scaled = add_gaussian_noise(X_train_scaled, noise_factor=0.05)\n",
    "\n",
    "X_val_scaled = scale_X_0_1_per_sequence(X_val)\n",
    "X_test_scaled = scale_X_0_1_per_sequence(X_test)\n",
    "\n",
    "# 2) Encode labels\n",
    "y_train_encoded = encode_labels(y_train)\n",
    "y_val_encoded   = encode_labels(y_val)\n",
    "y_test_encoded  = encode_labels(y_test)\n",
    "\n",
    "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "print(\"y_train_encoded shape:\", y_train_encoded.shape)\n",
    "print(\"Sample encoded labels:\", np.unique(y_train_encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9507, 150, 22)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Std Dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.510819</td>\n",
       "      <td>0.513494</td>\n",
       "      <td>0.255872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.497361</td>\n",
       "      <td>0.495462</td>\n",
       "      <td>0.259803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.526259</td>\n",
       "      <td>0.533976</td>\n",
       "      <td>0.258176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.510954</td>\n",
       "      <td>0.514083</td>\n",
       "      <td>0.256239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.150967</td>\n",
       "      <td>0.101580</td>\n",
       "      <td>0.159287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.502219</td>\n",
       "      <td>0.497780</td>\n",
       "      <td>0.307694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.503301</td>\n",
       "      <td>0.499722</td>\n",
       "      <td>0.306846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500998</td>\n",
       "      <td>0.500818</td>\n",
       "      <td>0.223750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>0.505629</td>\n",
       "      <td>0.265096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500879</td>\n",
       "      <td>0.501799</td>\n",
       "      <td>0.281889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500338</td>\n",
       "      <td>0.502102</td>\n",
       "      <td>0.229704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.498606</td>\n",
       "      <td>0.489165</td>\n",
       "      <td>0.298863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.507716</td>\n",
       "      <td>0.515037</td>\n",
       "      <td>0.300544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.502219</td>\n",
       "      <td>0.497780</td>\n",
       "      <td>0.307694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.410169</td>\n",
       "      <td>0.371655</td>\n",
       "      <td>0.267215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.507552</td>\n",
       "      <td>0.515670</td>\n",
       "      <td>0.275966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.513397</td>\n",
       "      <td>0.519111</td>\n",
       "      <td>0.321609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.510343</td>\n",
       "      <td>0.515804</td>\n",
       "      <td>0.307891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.505491</td>\n",
       "      <td>0.504158</td>\n",
       "      <td>0.302629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.503868</td>\n",
       "      <td>0.513321</td>\n",
       "      <td>0.325594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.503630</td>\n",
       "      <td>0.505172</td>\n",
       "      <td>0.308530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.508008</td>\n",
       "      <td>0.509258</td>\n",
       "      <td>0.285987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature  Min  Max      Mean    Median   Std Dev\n",
       "0         1  0.0  1.0  0.510819  0.513494  0.255872\n",
       "1         2  0.0  1.0  0.497361  0.495462  0.259803\n",
       "2         3  0.0  1.0  0.526259  0.533976  0.258176\n",
       "3         4  0.0  1.0  0.510954  0.514083  0.256239\n",
       "4         5  0.0  1.0  0.150967  0.101580  0.159287\n",
       "5         6  0.0  1.0  0.502219  0.497780  0.307694\n",
       "6         7  0.0  1.0  0.503301  0.499722  0.306846\n",
       "7         8  0.0  1.0  0.500998  0.500818  0.223750\n",
       "8         9  0.0  1.0  0.504143  0.505629  0.265096\n",
       "9        10  0.0  1.0  0.500879  0.501799  0.281889\n",
       "10       11  0.0  1.0  0.500338  0.502102  0.229704\n",
       "11       12  0.0  1.0  0.498606  0.489165  0.298863\n",
       "12       13  0.0  1.0  0.507716  0.515037  0.300544\n",
       "13       14  0.0  1.0  0.502219  0.497780  0.307694\n",
       "14       15  0.0  1.0  0.410169  0.371655  0.267215\n",
       "15       16  0.0  1.0  0.507552  0.515670  0.275966\n",
       "16       17  0.0  1.0  0.513397  0.519111  0.321609\n",
       "17       18  0.0  1.0  0.510343  0.515804  0.307891\n",
       "18       19  0.0  1.0  0.505491  0.504158  0.302629\n",
       "19       20  0.0  1.0  0.503868  0.513321  0.325594\n",
       "20       21  0.0  1.0  0.503630  0.505172  0.308530\n",
       "21       22  0.0  1.0  0.508008  0.509258  0.285987"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_stats = {\n",
    "    \"Min\": X_val_scaled.min(),\n",
    "    \"Max\": X_val_scaled.max(),\n",
    "    \"Mean\": X_val_scaled.mean(),\n",
    "    \"Median\": np.median(X_val_scaled),\n",
    "    \"Std Dev\": X_val_scaled.std(),\n",
    "}\n",
    "\n",
    "# Calculate feature-wise statistics\n",
    "feature_stats = []\n",
    "for feature in range(X_val_scaled.shape[2]):\n",
    "    feature_data = X_val_scaled[:, :, feature].flatten()\n",
    "    stats = {\n",
    "        \"Feature\": feature + 1,\n",
    "        \"Min\": feature_data.min(),\n",
    "        \"Max\": feature_data.max(),\n",
    "        \"Mean\": feature_data.mean(),\n",
    "        \"Median\": np.median(feature_data),\n",
    "        \"Std Dev\": feature_data.std(),\n",
    "    }\n",
    "    feature_stats.append(stats)\n",
    "\n",
    "feature_stats_df = pd.DataFrame(feature_stats)\n",
    "feature_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('X_train_scaled.npy', X_train_scaled)\n",
    "# np.save('X_val_scaled.npy', X_val_scaled)\n",
    "# np.save('X_test_scaled.npy', X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data validation passed! All features are scaled between 0 and 1.\n",
      "Data validation passed! All features are scaled between 0 and 1.\n",
      "Data validation passed! All features are scaled between 0 and 1.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def validate_scaled_data(X_scaled: np.ndarray, X_original: np.ndarray) -> None:\n",
    "    \"\"\"\n",
    "    Validates the scaled data by checking the following:\n",
    "    1. Each feature within each time step is scaled between 0 and 1.\n",
    "    2. The shape of the scaled data matches the original data.\n",
    "\n",
    "    Args:\n",
    "        X_scaled: Scaled data, should be of the same shape as X_original.\n",
    "        X_original: Original data before scaling.\n",
    "    \"\"\"\n",
    "    # 1. Check if the shape is consistent\n",
    "    if X_scaled.shape != X_original.shape:\n",
    "        raise ValueError(f\"Shape mismatch! Expected {X_original.shape}, but got {X_scaled.shape}\")\n",
    "    \n",
    "    # 2. Check if each feature is in the [0, 1] range\n",
    "    num_samples, input_window, num_features = X_scaled.shape\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        for j in range(num_features):\n",
    "            feature_min = np.min(X_scaled[i, :, j])\n",
    "            feature_max = np.max(X_scaled[i, :, j])\n",
    "            \n",
    "            if not (0 <= feature_min <= 1.001):\n",
    "                raise ValueError(f\"Min value for feature {j} in sample {i} is out of range: {feature_min}\")\n",
    "            if not (0 <= feature_max <= 1.001):\n",
    "                raise ValueError(f\"Max value for feature {j} in sample {i} is out of range: {feature_max}\")\n",
    "    \n",
    "    print(\"Data validation passed! All features are scaled between 0 and 1.\")\n",
    "    \n",
    "\n",
    "# Example usage with your data\n",
    "validate_scaled_data(X_train_scaled, X_train)\n",
    "validate_scaled_data(X_val_scaled, X_val)\n",
    "validate_scaled_data(X_test_scaled, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "def create_image_from_data(X_scaled: np.ndarray, sample_idx: int = 0) -> None:\n",
    "    \"\"\"\n",
    "    Creates an image (600x5 pixels) from the scaled data (values between 0 and 1).\n",
    "    The values are mapped from the range [0, 1] to [0, 255] for visual representation.\n",
    "\n",
    "    Args:\n",
    "        X_scaled: Scaled data array of shape (num_samples, 600, 5).\n",
    "        sample_idx: Index of the sample to visualize.\n",
    "    \"\"\"\n",
    "    # Get the selected sample (shape: 600, 5)\n",
    "    sample_data = X_scaled[sample_idx, :, :]\n",
    "\n",
    "    # Map the data from [0, 1] to [0, 255]\n",
    "    sample_data_mapped = (sample_data * 255).astype(np.uint8)\n",
    "\n",
    "    # Create the image (600x5)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(sample_data_mapped.T, cmap='gray', aspect='auto', origin='lower', interpolation='none')\n",
    "\n",
    "    # Set axis labels and title\n",
    "    plt.title(f\"Sample {sample_idx} - Scaled Data Visualization\")\n",
    "    plt.xlabel('Time Steps (600)')\n",
    "    plt.ylabel('Features (5)')\n",
    "    plt.colorbar(label='Pixel Value (0-255)')\n",
    "\n",
    "    # Show the image\n",
    "    plt.show()\n",
    "\n",
    "# Example usage to visualize the first sample\n",
    "create_image_from_data(X_test_scaled, sample_idx=-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Simple1DCNN(nn.Module):\n",
    "    def __init__(self, num_channels=5, seq_len=600, num_classes=3, dropout_p=0.3):\n",
    "        \"\"\"\n",
    "        An improved 1D CNN for time-series classification.\n",
    "\n",
    "        Args:\n",
    "            num_channels (int): Number of input channels (features). Defaults to 5 (e.g., open/high/low/close/volume).\n",
    "            seq_len (int): Number of timesteps in each sample (e.g., 600).\n",
    "            num_classes (int): Number of output classes (e.g., 3 for 'short','flat','long').\n",
    "            dropout_p (float): Dropout probability for regularization. Defaults to 0.3.\n",
    "        \"\"\"\n",
    "        super(Simple1DCNN, self).__init__()\n",
    "        \n",
    "        # -------------------------\n",
    "        # Convolution Block 1\n",
    "        # -------------------------\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=num_channels, \n",
    "            out_channels=32,\n",
    "            kernel_size=5,         # Larger kernel for broader context\n",
    "            stride=1, \n",
    "            padding=2              # \"same\" padding\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)  # Halves sequence length: 600 -> 300\n",
    "\n",
    "        # -------------------------\n",
    "        # Convolution Block 2\n",
    "        # -------------------------\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=32, \n",
    "            out_channels=64,\n",
    "            kernel_size=5, \n",
    "            stride=1, \n",
    "            padding=2\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)  # 300 -> 150\n",
    "\n",
    "        # -------------------------\n",
    "        # Convolution Block 3\n",
    "        # -------------------------\n",
    "        self.conv3 = nn.Conv1d(\n",
    "            in_channels=64, \n",
    "            out_channels=128,\n",
    "            kernel_size=3, \n",
    "            stride=1, \n",
    "            padding=1\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2)  # 150 -> 75\n",
    "\n",
    "        # After 3 poolings, seq_len -> seq_len / 8\n",
    "        # so final sequence length = 600 / 2 / 2 / 2 = 75\n",
    "        # out channels = 128\n",
    "        # flattened size = 128 * 75 = 9600\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "\n",
    "        # self.fc = nn.Linear(128 * (seq_len // 8), num_classes)\n",
    "\n",
    "        # OPTIONAL: If you want to do global average pooling (instead of flattening),\n",
    "        # you can comment out the above fc dimension logic and do:\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x shape: (batch_size, channels=num_channels, seq_len)\n",
    "        \"\"\"\n",
    "        # -------------------------\n",
    "        # Block 1\n",
    "        # -------------------------\n",
    "        x = self.conv1(x)    # (batch, 32, seq_len=600)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)    # (batch, 32, 300)\n",
    "\n",
    "        # -------------------------\n",
    "        # Block 2\n",
    "        # -------------------------\n",
    "        x = self.conv2(x)    # (batch, 64, 300)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)    # (batch, 64, 150)\n",
    "\n",
    "        # -------------------------\n",
    "        # Block 3\n",
    "        # -------------------------\n",
    "        x = self.conv3(x)    # (batch, 128, 150)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)    # (batch, 128, 75)\n",
    "\n",
    "        # -------------------------\n",
    "        # Flatten or Global Pool\n",
    "        # -------------------------\n",
    "        # # 1) Flatten approach\n",
    "        # x = x.view(x.size(0), -1)  # => (batch, 128 * 75)\n",
    "        \n",
    "        # # 2) Dropout for regularization\n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        # # 3) Fully connected output\n",
    "        # x = self.fc(x)  # => (batch, num_classes=3)\n",
    "\n",
    "        # OPTIONAL (Global Pooling) approach:\n",
    "        x = self.global_pool(x)  # => (batch, 128, 1)\n",
    "        x = x.squeeze(-1)        # => (batch, 128)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = Simple1DCNN(num_channels=5, seq_len=600, num_classes=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class Enlarged1DCNN(nn.Module):\n",
    "    def __init__(self, num_channels=5, seq_len=600, num_classes=3, dropout_p=0.4):\n",
    "        \"\"\"\n",
    "        An enlarged 1D CNN for time-series classification with enhanced capacity and regularization.\n",
    "    \n",
    "        Args:\n",
    "            num_channels (int): Number of input channels (features). Defaults to 5 (e.g., open/high/low/close/volume).\n",
    "            seq_len (int): Number of timesteps in each sample (e.g., 600).\n",
    "            num_classes (int): Number of output classes (e.g., 3 for 'short','flat','long').\n",
    "            dropout_p (float): Dropout probability for regularization. Defaults to 0.4.\n",
    "        \"\"\"\n",
    "        super(Enlarged1DCNN, self).__init__()\n",
    "        \n",
    "        # -------------------------\n",
    "        # Convolution Block 1\n",
    "        # -------------------------\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=num_channels, \n",
    "            out_channels=64,           # Increased from 32 to 64\n",
    "            kernel_size=7,             \n",
    "            stride=1, \n",
    "            padding=3                  \n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)  # 600 -> 300\n",
    "        self.dropout1 = nn.Dropout(p=dropout_p)\n",
    "        \n",
    "        # -------------------------\n",
    "        # Convolution Block 2\n",
    "        # -------------------------\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=64, \n",
    "            out_channels=128,          # Increased from 64 to 128\n",
    "            kernel_size=5, \n",
    "            stride=1, \n",
    "            padding=2\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)  # 300 -> 150\n",
    "        self.dropout2 = nn.Dropout(p=dropout_p)\n",
    "        \n",
    "        # -------------------------\n",
    "        # Convolution Block 3\n",
    "        # -------------------------\n",
    "        self.conv3 = nn.Conv1d(\n",
    "            in_channels=128, \n",
    "            out_channels=256,          # Increased from 128 to 256\n",
    "            kernel_size=3, \n",
    "            stride=1, \n",
    "            padding=1\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2)  # 150 -> 75\n",
    "        self.dropout3 = nn.Dropout(p=dropout_p)\n",
    "        \n",
    "        # -------------------------\n",
    "        # Convolution Block 4 (Optional)\n",
    "        # -------------------------\n",
    "        self.conv4 = nn.Conv1d(\n",
    "            in_channels=256, \n",
    "            out_channels=512,          # Additional layer\n",
    "            kernel_size=3, \n",
    "            stride=1, \n",
    "            padding=1\n",
    "        )\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.pool4 = nn.MaxPool1d(kernel_size=2)  # 75 -> 37 (rounded down)\n",
    "        self.dropout4 = nn.Dropout(p=dropout_p)\n",
    "        \n",
    "        # -------------------------\n",
    "        # Fully Connected Layers\n",
    "        # -------------------------\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)  # Global Average Pooling\n",
    "        self.fc1 = nn.Linear(512, 256)              # Increased size\n",
    "        self.bn_fc1 = nn.BatchNorm1d(256)\n",
    "        self.dropout_fc1 = nn.Dropout(p=dropout_p)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn_fc2 = nn.BatchNorm1d(128)\n",
    "        self.dropout_fc2 = nn.Dropout(p=dropout_p)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the network.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, channels, seq_len)\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Output logits of shape (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "        # -------------------------\n",
    "        # Block 1\n",
    "        # -------------------------\n",
    "        x = self.conv1(x)       # (batch, 64, 600)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)       # (batch, 64, 300)\n",
    "        x = self.dropout1(x)\n",
    "    \n",
    "        # -------------------------\n",
    "        # Block 2\n",
    "        # -------------------------\n",
    "        x = self.conv2(x)       # (batch, 128, 300)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)       # (batch, 128, 150)\n",
    "        x = self.dropout2(x)\n",
    "    \n",
    "        # -------------------------\n",
    "        # Block 3\n",
    "        # -------------------------\n",
    "        x = self.conv3(x)       # (batch, 256, 150)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)       # (batch, 256, 75)\n",
    "        x = self.dropout3(x)\n",
    "    \n",
    "        # -------------------------\n",
    "        # Block 4 (Optional)\n",
    "        # -------------------------\n",
    "        x = self.conv4(x)       # (batch, 512, 75)\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool4(x)       # (batch, 512, 37)\n",
    "        x = self.dropout4(x)\n",
    "    \n",
    "        # -------------------------\n",
    "        # Global Pooling and Fully Connected Layers\n",
    "        # -------------------------\n",
    "        x = self.global_pool(x) # (batch, 512, 1)\n",
    "        x = x.squeeze(-1)       # (batch, 512)\n",
    "        \n",
    "        x = self.fc1(x)         # (batch, 256)\n",
    "        x = self.bn_fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_fc1(x)\n",
    "        \n",
    "        x = self.fc2(x)         # (batch, 128)\n",
    "        x = self.bn_fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_fc2(x)\n",
    "        \n",
    "        x = self.fc3(x)         # (batch, num_classes)\n",
    "    \n",
    "        return x\n",
    "    \n",
    "model = Enlarged1DCNN(num_channels=5, seq_len=600, num_classes=3, dropout_p=0.6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, dropout_p=0.4):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        # If input and output channels differ, adjust the residual connection\n",
    "        if in_channels != out_channels:\n",
    "            self.residual = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "        else:\n",
    "            self.residual = nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.residual(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResidualEnlarged1DCNN(nn.Module):\n",
    "    def __init__(self, num_channels=5, seq_len=600, num_classes=3, dropout_p=0.4):\n",
    "        super(ResidualEnlarged1DCNN, self).__init__()\n",
    "        \n",
    "        # Initial convolution\n",
    "        self.conv_initial = nn.Conv1d(num_channels, 64, kernel_size=7, stride=1, padding=3)\n",
    "        self.bn_initial = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)  # 600 -> 300\n",
    "        self.dropout_initial = nn.Dropout(p=dropout_p)\n",
    "        \n",
    "        # Residual Blocks\n",
    "        self.res_block1 = ResidualBlock(64, 128, kernel_size=5, padding=2, dropout_p=dropout_p)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)  # 300 -> 150\n",
    "        self.dropout2 = nn.Dropout(p=dropout_p)\n",
    "        \n",
    "        self.res_block2 = ResidualBlock(128, 256, kernel_size=3, padding=1, dropout_p=dropout_p)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2)  # 150 -> 75\n",
    "        self.dropout3 = nn.Dropout(p=dropout_p)\n",
    "        \n",
    "        self.res_block3 = ResidualBlock(256, 512, kernel_size=3, padding=1, dropout_p=dropout_p)\n",
    "        self.pool4 = nn.MaxPool1d(kernel_size=2)  # 75 -> 37\n",
    "        self.dropout4 = nn.Dropout(p=dropout_p)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)  # (batch, 512, 1)\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(256)\n",
    "        self.dropout_fc1 = nn.Dropout(p=dropout_p)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn_fc2 = nn.BatchNorm1d(128)\n",
    "        self.dropout_fc2 = nn.Dropout(p=dropout_p)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initial convolution\n",
    "        x = self.conv_initial(x)\n",
    "        x = self.bn_initial(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout_initial(x)\n",
    "        \n",
    "        # Residual Block 1\n",
    "        x = self.res_block1(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # Residual Block 2\n",
    "        x = self.res_block2(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        # Residual Block 3\n",
    "        x = self.res_block3(x)\n",
    "        x = self.pool4(x)\n",
    "        x = self.dropout4(x)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.global_pool(x)  # (batch, 512, 1)\n",
    "        x = x.squeeze(-1)        # (batch, 512)\n",
    "        \n",
    "        x = self.fc1(x)          # (batch, 256)\n",
    "        x = self.bn_fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout_fc1(x)\n",
    "        \n",
    "        x = self.fc2(x)          # (batch, 128)\n",
    "        x = self.bn_fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout_fc2(x)\n",
    "        \n",
    "        x = self.fc3(x)          # (batch, num_classes)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize the residual enlarged model\n",
    "model = ResidualEnlarged1DCNN(num_channels=5, seq_len=600, num_classes=3, dropout_p=0.4)\n",
    "\n",
    "# The rest of the training setup remains the same as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels, \n",
    "        out_channels, \n",
    "        kernel_size=3, \n",
    "        stride=1, \n",
    "        padding=1, \n",
    "        dropout_p=0.4\n",
    "    ):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, 1, padding)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        # If input and output channels differ or stride !=1, adjust the residual connection\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.residual = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.residual = nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.residual(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResidualEnlarged1DCNN2(nn.Module):\n",
    "    def __init__(self, num_channels=5, seq_len=600, num_classes=3, dropout_p=0.4):\n",
    "        super(ResidualEnlarged1DCNN2, self).__init__()\n",
    "        \n",
    "        # Initial convolution with stride=2 for initial downsampling\n",
    "        self.conv_initial = nn.Conv1d(num_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn_initial = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)  # Further downsampling\n",
    "        self.dropout_initial = nn.Dropout(p=dropout_p)\n",
    "        \n",
    "        # Residual Blocks\n",
    "        self.res_block1 = ResidualBlock(64, 128, kernel_size=5, stride=2, padding=2, dropout_p=dropout_p)\n",
    "        self.dropout2 = nn.Dropout(p=dropout_p)\n",
    "        \n",
    "        self.res_block2 = ResidualBlock(128, 256, kernel_size=3, stride=2, padding=1, dropout_p=dropout_p)\n",
    "        self.dropout3 = nn.Dropout(p=dropout_p)\n",
    "        \n",
    "        self.res_block3 = ResidualBlock(256, 512, kernel_size=3, stride=2, padding=1, dropout_p=dropout_p)\n",
    "        self.dropout4 = nn.Dropout(p=dropout_p)\n",
    "        \n",
    "        # Fully Connected Layers with Global Avg and Max Pooling\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)  # (batch, 512, 1)\n",
    "        self.global_max_pool = nn.AdaptiveMaxPool1d(1)  # (batch, 512, 1)\n",
    "        self.fc1 = nn.Linear(512 * 2, 256)  # Concatenated features\n",
    "        self.bn_fc1 = nn.BatchNorm1d(256)\n",
    "        self.dropout_fc1 = nn.Dropout(p=dropout_p)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn_fc2 = nn.BatchNorm1d(128)\n",
    "        self.dropout_fc2 = nn.Dropout(p=dropout_p)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initial convolution\n",
    "        x = self.conv_initial(x)          # Output shape: (batch, 64, seq_len/2)\n",
    "        x = self.bn_initial(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)                 # Output shape: (batch, 64, seq_len/4)\n",
    "        x = self.dropout_initial(x)\n",
    "        \n",
    "        # Residual Block 1\n",
    "        x = self.res_block1(x)            # Output shape: (batch, 128, seq_len/8)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # Residual Block 2\n",
    "        x = self.res_block2(x)            # Output shape: (batch, 256, seq_len/16)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        # Residual Block 3\n",
    "        x = self.res_block3(x)            # Output shape: (batch, 512, seq_len/32)\n",
    "        x = self.dropout4(x)\n",
    "        \n",
    "        # Global Pooling\n",
    "        avg_pooled = self.global_avg_pool(x)  # Shape: (batch, 512, 1)\n",
    "        max_pooled = self.global_max_pool(x)  # Shape: (batch, 512, 1)\n",
    "        x = torch.cat((avg_pooled, max_pooled), dim=1)  # Shape: (batch, 1024, 1)\n",
    "        x = x.squeeze(-1)                        # Shape: (batch, 1024)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        x = self.fc1(x)                          # Shape: (batch, 256)\n",
    "        x = self.bn_fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout_fc1(x)\n",
    "        \n",
    "        x = self.fc2(x)                          # Shape: (batch, 128)\n",
    "        x = self.bn_fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout_fc2(x)\n",
    "        \n",
    "        x = self.fc3(x)                          # Shape: (batch, num_classes)\n",
    "        \n",
    "        return x\n",
    "model = ResidualEnlarged1DCNN2(num_channels=5, seq_len=600, num_classes=3, dropout_p=0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureSpecific1DCNN_MaxPooling(\n",
      "  (cnn_blocks): ModuleList(\n",
      "    (0-21): 22 x Sequential(\n",
      "      (0): Conv1d(1, 32, kernel_size=(7,), stride=(3,))\n",
      "      (1): ReLU()\n",
      "      (2): Conv1d(32, 32, kernel_size=(7,), stride=(3,))\n",
      "      (3): ReLU()\n",
      "      (4): Conv1d(32, 32, kernel_size=(7,), stride=(7,))\n",
      "      (5): ReLU()\n",
      "      (6): AdaptiveMaxPool1d(output_size=1)\n",
      "    )\n",
      "  )\n",
      "  (final_mlp): Sequential(\n",
      "    (0): Linear(in_features=704, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.4, inplace=False)\n",
      "    (3): Linear(in_features=64, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FeatureSpecific1DCNN_MaxPooling(nn.Module):\n",
    "    def __init__(self, num_channels=5, seq_len=600, num_classes=3, dropout_p=0.4):\n",
    "        \"\"\"\n",
    "        Initializes the FeatureSpecific1DCNN model with 3 CNN layers per feature,\n",
    "        per-branch max pooling, and a final MLP.\n",
    "\n",
    "        Args:\n",
    "            num_channels (int): Number of distinct features (default: 5).\n",
    "            seq_len (int): Length of each time series sequence (default: 600).\n",
    "            num_classes (int): Number of output classes (default: 3).\n",
    "            dropout_p (float): Dropout probability (default: 0.4).\n",
    "        \"\"\"\n",
    "        super(FeatureSpecific1DCNN_MaxPooling, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.seq_len = seq_len\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        # Define the CNN blocks to reduce sequence length from 600 to 9 in 3 layers\n",
    "        self.cnn_blocks = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(in_channels=1, out_channels=32, kernel_size=7, stride=3),  # 600 -> 198\n",
    "                nn.ReLU(),\n",
    "                nn.Conv1d(in_channels=32, out_channels=32, kernel_size=7, stride=3), # 198 -> 64\n",
    "                nn.ReLU(),\n",
    "                nn.Conv1d(in_channels=32, out_channels=32, kernel_size=7, stride=7), # 64 -> 9\n",
    "                nn.ReLU(),\n",
    "                nn.AdaptiveMaxPool1d(output_size=1)  # Global max pooling over the sequence length\n",
    "            ) for _ in range(num_channels)\n",
    "        ])\n",
    "\n",
    "        # Each branch will now output (batch_size, 32, 1) after pooling\n",
    "        # Flattened size per branch: 32\n",
    "        self.flattened_size_per_branch = 32\n",
    "\n",
    "        # Calculate the concatenated size from all branches\n",
    "        self.concatenated_size = num_channels * self.flattened_size_per_branch  # e.g., 5 * 32 = 160\n",
    "\n",
    "        # Define the final MLP\n",
    "        self.final_mlp = nn.Sequential(\n",
    "            nn.Linear(self.concatenated_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, num_channels, seq_len).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Logits for each class.\n",
    "        \"\"\"\n",
    "        # List to hold outputs from each CNN branch\n",
    "        branch_outputs = []\n",
    "\n",
    "        # Process each feature through its corresponding CNN branch\n",
    "        for i in range(self.num_channels):\n",
    "            # Extract the i-th feature: shape (batch_size, 1, seq_len)\n",
    "            feature = x[:, i].unsqueeze(1)\n",
    "            cnn_out = self.cnn_blocks[i](feature)  # Shape: (batch_size, 32, 1)\n",
    "            cnn_out = cnn_out.view(cnn_out.size(0), -1)  # Flatten: (batch_size, 32)\n",
    "            branch_outputs.append(cnn_out)\n",
    "\n",
    "        # Concatenate all branch outputs: shape (batch_size, 160)\n",
    "        concatenated = torch.cat(branch_outputs, dim=1)  # 5 branches * 32 = 160\n",
    "\n",
    "        # Pass through the final MLP\n",
    "        logits = self.final_mlp(concatenated)  # Shape: (batch_size, num_classes)\n",
    "\n",
    "        return logits\n",
    "\n",
    "# Instantiate the modified model\n",
    "model = FeatureSpecific1DCNN_MaxPooling(num_channels=22, seq_len=600, num_classes=3, dropout_p=0.4)\n",
    "\n",
    "# Print the model architecture to verify changes\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesModel(\n",
      "  (conv1): Conv1d(5, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (relu): ReLU()\n",
      "  (dropout1): Dropout(p=0.8, inplace=False)\n",
      "  (conv2): Conv1d(64, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (dropout2): Dropout(p=0.4, inplace=False)\n",
      "  (fc1): Linear(in_features=2400, out_features=16, bias=True)\n",
      "  (dropout3): Dropout(p=0.4, inplace=False)\n",
      "  (fc): Linear(in_features=16, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class TimeSeriesModel(nn.Module): \n",
    "    def __init__(self, num_channels=5, seq_len=150, num_classes=3, dropout_p=0.4):\n",
    "        super(TimeSeriesModel, self).__init__()\n",
    "        \n",
    "        # First Convolutional Layer\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=num_channels,      # 5 features: open, close, high, low, volume\n",
    "            out_channels=64,               # Number of filters\n",
    "            kernel_size=3,                 # Size of the convolutional kernel\n",
    "            padding=1                      # To maintain the sequence length\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.8)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=64,      # 5 features: open, close, high, low, volume\n",
    "            out_channels=16,               # Number of filters\n",
    "            kernel_size=3,                 # Size of the convolutional kernel\n",
    "            padding=1                      # To maintain the sequence length\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.4)\n",
    "        \n",
    "        # Optionally, add more convolutional layers or pooling layers here\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        self.fc1 = nn.Linear(2400, 16)\n",
    "        self.dropout3 = nn.Dropout(0.4)\n",
    "\n",
    "        self.fc = nn.Linear(16, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)           # Apply convolution: (batch_size, 64, seq_len)\n",
    "        x = self.dropout1(x)         # Apply dropout\n",
    "        x = self.relu(x)  \n",
    "        x = self.conv2(x)           # Apply convolution: (batch_size, 64, seq_len)\n",
    "        x = self.dropout2(x)         # Apply dropout\n",
    "        x = self.relu(x)          # Apply ReLU activation\n",
    "        x = x.view(x.size(0), -1)  # Flatten to (batch_size, 64*seq_len)\n",
    "        x = self.fc1(x)              # Fully connected layer to (batch_size, num_classes)\n",
    "        x = self.dropout3(x)         # Apply dropout\n",
    "        x = self.fc(x)              # Fully connected layer to (batch_size, num_classes)\n",
    "        return x\n",
    "    \n",
    "model = TimeSeriesModel(num_channels=5, seq_len=150, num_classes=3, dropout_p=0.6)\n",
    "\n",
    "# Print the model architecture to verify changes\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridCNN(\n",
      "  (shared_conv1): Conv1d(22, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (shared_relu): ReLU()\n",
      "  (shared_dropout): Dropout1d(p=0.4, inplace=False)\n",
      "  (feature_cnns): ModuleList(\n",
      "    (0-21): 22 x Sequential(\n",
      "      (0): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): ReLU()\n",
      "      (2): Dropout1d(p=0.6, inplace=False)\n",
      "      (3): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (4): ReLU()\n",
      "      (5): Dropout1d(p=0.4, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (conv_reduce1): Conv1d(736, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "  (relu1): ReLU()\n",
      "  (dropout1): Dropout1d(p=0.5, inplace=False)\n",
      "  (conv_reduce2): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "  (relu2): ReLU()\n",
      "  (dropout2): Dropout1d(p=0.5, inplace=False)\n",
      "  (global_pool): AdaptiveAvgPool1d(output_size=3)\n",
      "  (fc1): Linear(in_features=768, out_features=256, bias=True)\n",
      "  (dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (fc_final): Linear(in_features=256, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class HybridCNN(nn.Module):\n",
    "    def __init__(self, num_features=22, seq_len=150, num_classes=3, dropout_p=0.8):\n",
    "        super(HybridCNN, self).__init__()\n",
    "        \n",
    "        # Shared Convolutional Layer\n",
    "        self.shared_conv1 = nn.Conv1d(\n",
    "            in_channels=num_features,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "        self.shared_relu = nn.ReLU()\n",
    "        self.shared_dropout = nn.Dropout1d(p=0.4)\n",
    "        \n",
    "        # Feature-Specific Convolutional Layers\n",
    "        self.feature_cnns = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(1, 128, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout1d(p=0.6),\n",
    "                nn.Conv1d(128, 32, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout1d(p=0.4)\n",
    "            )\n",
    "            for _ in range(num_features)\n",
    "        ])\n",
    "        \n",
    "        # Additional Convolutional Layers to Replace fc1\n",
    "        self.conv_reduce1 = nn.Conv1d(\n",
    "            in_channels=32 * (1 + num_features),\n",
    "            out_channels=128,\n",
    "            kernel_size=3,\n",
    "            stride=2,  # Reduce sequence length by half\n",
    "            padding=1\n",
    "        )\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout1d(p=0.5)\n",
    "        \n",
    "        self.conv_reduce2 = nn.Conv1d(\n",
    "            in_channels=128,\n",
    "            out_channels=256,\n",
    "            kernel_size=3,\n",
    "            stride=2,  # Further reduce sequence length\n",
    "            padding=1\n",
    "        )\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout1d(p=0.5)\n",
    "        \n",
    "        # Global Average Pooling to get fixed-size vector\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(3)  # Adjust as needed to reach desired size\n",
    "        \n",
    "        # Final Fully Connected Layer\n",
    "        self.fc1 = nn.Linear(256 * 3, 256)  # 256 channels * 3 pooled features = 768\n",
    "        self.dropout3 = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.fc_final = nn.Linear(256, num_classes)  # 256 channels * 3 pooled features = 768\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input shape: (batch_size, num_features=22, seq_len=150)\n",
    "        \"\"\"\n",
    "        # Shared Convolution\n",
    "        shared_out = self.shared_conv1(x)  # Shape: (batch_size, 32, 150)\n",
    "        shared_out = self.shared_relu(shared_out)\n",
    "        shared_out = self.shared_dropout(shared_out)\n",
    "        \n",
    "        # Feature-Specific Convolutions\n",
    "        feature_outputs = []\n",
    "        for i, cnn in enumerate(self.feature_cnns):\n",
    "            feature = x[:, i:i+1, :]  # Shape: (batch_size, 1, 150)\n",
    "            feature_out = cnn(feature)  # Shape: (batch_size, 32, 150)\n",
    "            feature_outputs.append(feature_out)\n",
    "        \n",
    "        # Concatenate All Outputs\n",
    "        all_features = torch.cat([shared_out] + feature_outputs, dim=1)  # Shape: (batch_size, 32*(1+22), 150) = (batch_size, 736, 150)\n",
    "        \n",
    "        # Replace Flattening with Additional Convolutions\n",
    "        x = self.conv_reduce1(all_features)  # Shape: (batch_size, 128, 75)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.conv_reduce2(x)  # Shape: (batch_size, 256, 38) assuming stride=2\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        x = self.global_pool(x)  # Shape: (batch_size, 256, 3)\n",
    "        x = x.view(x.size(0), -1)  # Shape: (batch_size, 768)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout3(x)\n",
    "        # Final Classification Layer\n",
    "        x = self.fc_final(x)  # Shape: (batch_size, num_classes)\n",
    "        return x\n",
    "\n",
    "# Instantiate the modified model\n",
    "model = HybridCNN(num_features=22, seq_len=150, num_classes=3, dropout_p=0.8)\n",
    "\n",
    "# Print the modified model architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reconstruct the model architecture\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model = HybridCNN(num_features=22, seq_len=150, num_classes=3)\n",
    "\n",
    "# # Load the saved state dictionary\n",
    "# model.load_state_dict(torch.load(r\"C:\\GitCnn\\CnnTrading\\CnnTrans\\HybridCNN_best_on_valid_state_dict.pth\", map_location=device))\n",
    "\n",
    "# # Move to device\n",
    "# model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Suppose X_train_scaled.shape = (19000, 600, 5)\n",
    "# and y_train_encoded.shape = (19000,)\n",
    "X_train_transposed = np.transpose(X_train_scaled, (0, 2, 1))  # (19000, 5, 600)\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # Convert numpy arrays to PyTorch tensors\n",
    "        self.X = torch.from_numpy(X).float()  # shape: (num_samples, channels, seq_len)\n",
    "        self.y = torch.from_numpy(y).long()   # shape: (num_samples,)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Return (features, label) for sample 'idx'\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = TimeSeriesDataset(X_train_transposed, y_train_encoded)\n",
    "\n",
    "batch_size = 512\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Suppose X_val_scaled.shape = (val_size, 600, 5)\n",
    "# Suppose y_val_encoded.shape = (val_size,)\n",
    "\n",
    "# 1) Transpose\n",
    "X_val_transposed = np.transpose(np.concatenate((X_val_scaled, X_test_scaled), axis=0), (0, 2, 1))  # shape: (val_size, 5, 600)\n",
    "\n",
    "# 2) Wrap in a Dataset\n",
    "val_dataset = TimeSeriesDataset(X_val_transposed, np.concatenate((y_val_encoded, y_test_encoded), axis=0))\n",
    "\n",
    "# 3) Create DataLoader (batch_size can match or differ from train)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitCnn\\CnnTrading\\CnnTrans\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.1021, Acc: 0.3238\n",
      "Epoch 2, Loss: 1.0996, Acc: 0.3288\n",
      "Epoch 3, Loss: 1.0996, Acc: 0.3375\n",
      "Epoch 4, Loss: 1.0994, Acc: 0.3317\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Assume train_loader and val_loader are predefined DataLoader instances\n",
    "# Also assume that the model is defined and instantiated as `model`\n",
    "\n",
    "# Initialize the device, model, criterion, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "l2_lambda = 1e-4  # You can adjust this value based on your needs\n",
    "\n",
    "# Initialize the optimizer with weight_decay for L2 regularization\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=l2_lambda)\n",
    "\n",
    "# Initialize the learning rate scheduler\n",
    "# Here, ReduceLROnPlateau reduces the LR by a factor of 0.1 if validation loss doesn't improve for 5 epochs\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=15, verbose=True)\n",
    "\n",
    "# Set the desired validation loss threshold\n",
    "validation_threshold = 0.25\n",
    "\n",
    "epoch_loss = 1\n",
    "epoch = 0\n",
    "\n",
    "while True:\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Training loop\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        correct += (pred == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    epoch += 1\n",
    "    \n",
    "    print(f\"Epoch {epoch}, Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\")\n",
    "    \n",
    "    # Validation every 5 epochs\n",
    "    if epoch % 5 == 0:\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # To collect predictions and true labels for further metrics\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                outputs = model(X_batch)              # shape: (batch_size, num_classes)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "\n",
    "                val_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "                # Predictions\n",
    "                _, predicted = torch.max(outputs, 1)  # shape: (batch_size,)\n",
    "                \n",
    "                correct += (predicted == y_batch).sum().item()\n",
    "                total += y_batch.size(0)\n",
    "                \n",
    "                # Store predictions & labels for confusion matrix, etc.\n",
    "                all_preds.append(predicted.cpu().numpy())\n",
    "                all_labels.append(y_batch.cpu().numpy())\n",
    "\n",
    "        # Convert lists of arrays into a single 1D array\n",
    "        all_preds = np.concatenate(all_preds)\n",
    "        all_labels = np.concatenate(all_labels)\n",
    "\n",
    "        val_loss /= total\n",
    "        val_acc = correct / total\n",
    "\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # --------------------------------------------------------------------------\n",
    "        # Additional Metrics\n",
    "        # --------------------------------------------------------------------------\n",
    "\n",
    "        # 1) Confusion Matrix\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm)\n",
    "\n",
    "        # 2) Classification Report\n",
    "        #    If you have 3 classes: 0=\"short\", 1=\"flat\", 2=\"long\" (example)\n",
    "        target_names = [\"short\", \"flat\", \"long\"]  # adjust if needed\n",
    "        report = classification_report(all_labels, all_preds, target_names=target_names)\n",
    "        print(\"Classification Report:\")\n",
    "        print(report)\n",
    "        \n",
    "        # Step the scheduler with the validation loss\n",
    "        scheduler.step(val_loss)\n",
    "        print(f\"Learning Rate after scheduler step: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        # If the validation loss is acceptable, stop training\n",
    "        if val_loss <= validation_threshold or optimizer.param_groups[0]['lr'] < 1e-8:\n",
    "            print(f\"Validation loss has reached the threshold of {validation_threshold:.4f}, stopping training.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "print(f\"Final model saved to {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [\"short\", \"flat\", \"long\"]  # Adjust based on your class names\n",
    "report = classification_report(all_labels, all_preds, target_names=target_names)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# To collect predictions and true labels for further metrics\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in val_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        outputs = model(X_batch)              # shape: (batch_size, num_classes)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        val_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        # Predictions\n",
    "        _, predicted = torch.max(outputs, 1)  # shape: (batch_size,)\n",
    "        \n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "        \n",
    "        # Store predictions & labels for confusion matrix, etc.\n",
    "        all_preds.append(predicted.cpu().numpy())\n",
    "        all_labels.append(y_batch.cpu().numpy())\n",
    "\n",
    "# Convert lists of arrays into a single 1D array\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "val_loss /= total\n",
    "val_acc = correct / total\n",
    "\n",
    "print(f\"Validation Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}\")\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Additional Metrics\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "target_names = [\"short\", \"flat\", \"long\"]  # adjust if needed\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names) \n",
    "disp.plot() \n",
    "# And show it: \n",
    "plt.show()\n",
    "# 2) Classification Report\n",
    "#    If you have 3 classes: 0=\"short\", 1=\"flat\", 2=\"long\" (example)\n",
    "report = classification_report(all_labels, all_preds, target_names=target_names)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose X_test_scaled.shape = (test_size, 600, 5)\n",
    "# Suppose y_test_encoded.shape = (test_size,)\n",
    "\n",
    "# 1) Transpose\n",
    "X_test_transposed = np.transpose(X_test_scaled, (0, 2, 1))  # shape: (test_size, 5, 600)\n",
    "\n",
    "# 2) Wrap in a Dataset\n",
    "test_dataset = TimeSeriesDataset(X_test_transposed, y_test_encoded)\n",
    "\n",
    "# 3) Create DataLoader (batch_size can match or differ from train)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# To collect predictions and true labels for further metrics\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        outputs = model(X_batch)              # shape: (batch_size, num_classes)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        val_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        # Predictions\n",
    "        _, predicted = torch.max(outputs, 1)  # shape: (batch_size,)\n",
    "        \n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "        \n",
    "        # Store predictions & labels for confusion matrix, etc.\n",
    "        all_preds.append(predicted.cpu().numpy())\n",
    "        all_labels.append(y_batch.cpu().numpy())\n",
    "\n",
    "# Convert lists of arrays into a single 1D array\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "val_loss /= total\n",
    "val_acc = correct / total\n",
    "\n",
    "print(f\"Validation Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}\")\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Additional Metrics\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# 1) Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# 2) Classification Report\n",
    "#    If you have 3 classes: 0=\"short\", 1=\"flat\", 2=\"long\" (example)\n",
    "target_names = [\"short\", \"flat\", \"long\"]  # adjust if needed\n",
    "report = classification_report(all_labels, all_preds, target_names=target_names)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do inference on a single sample from X_test\n",
    "predicted_labels = []\n",
    "model.eval()\n",
    "\n",
    "for X_single in X_test_slice:\n",
    "    X_single_scaled = MinMaxScaler().fit_transform(X_single)  # shape (600,5)\n",
    "    X_single_scaled = np.expand_dims(X_single_scaled, axis=0)  # => (1,600,5)\n",
    "    X_single_transposed = np.transpose(X_single_scaled, (0, 2, 1))  # => (1,5,600)\n",
    "    X_single_tensor = torch.from_numpy(X_single_transposed).float().to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(X_single_tensor)   # => shape (1,3)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        predicted_label = predicted.item()  # 0,1,2\n",
    "\n",
    "    label_map = {0:\"short\",1:\"flat\",2:\"long\"}\n",
    "    predicted_labels.append(label_map[predicted_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kek = labels_test_slice == predicted_labels\n",
    "unique, counts = np.unique(kek, return_counts=True)\n",
    "\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_trading_statistics(X_test_slice, y_test_slice, labels_test_slice,  500, 100)\n",
    "# compute_profit(X, y, predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_trading_statistics(X_test_slice, y_test_slice, predicted_labels, 500, 100)\n",
    "# compute_profit(X, y, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_input_output_combined_with_label(\n",
    "    input_sequence: np.ndarray,\n",
    "    output_sequence: np.ndarray,\n",
    "    label: str,\n",
    "    title: str = \"Input + Output Window on One Chart\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots both input and output windows on a single candlestick chart.\n",
    "    The output window candles will be overlaid in a color depending on 'label':\n",
    "      - long -> green\n",
    "      - short -> red\n",
    "      - flat -> blue\n",
    "\n",
    "    Args:\n",
    "        input_sequence (np.ndarray): OHLCV data for the input window (shape: [N, >=5])\n",
    "        output_sequence (np.ndarray): OHLCV data for the output window (shape: [M, >=5])\n",
    "        label (str): The trading signal for the output window ('long', 'short', 'flat').\n",
    "        title (str): The title of the chart.\n",
    "    \"\"\"\n",
    "\n",
    "    # Use only the first 5 columns (OHLCV)\n",
    "    input_sequence = input_sequence[:, :5]\n",
    "    output_sequence = output_sequence[:, :5]\n",
    "\n",
    "    # Generate a continuous datetime index for plotting\n",
    "    input_dates = pd.date_range(start=\"2023-01-01\", periods=len(input_sequence), freq=\"min\")\n",
    "    output_dates = pd.date_range(start=input_dates[-1] + pd.Timedelta(minutes=1), periods=len(output_sequence), freq=\"min\")\n",
    "\n",
    "    # Convert to DataFrames with appropriate columns\n",
    "    input_df = pd.DataFrame(input_sequence, columns=[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"], index=input_dates)\n",
    "    output_df = pd.DataFrame(output_sequence, columns=[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"], index=output_dates)\n",
    "\n",
    "    # Concatenate input and output DataFrames\n",
    "    combined_df = pd.concat([input_df, output_df])\n",
    "\n",
    "    # Create a market colors style for the input sequence (standard green/red)\n",
    "    input_market_colors = mpf.make_marketcolors(\n",
    "        up='green', down='red', edge='inherit', wick='inherit', volume='inherit'\n",
    "    )\n",
    "    input_style = mpf.make_mpf_style(marketcolors=input_market_colors)\n",
    "\n",
    "    # Plot the combined data with the input sequence style\n",
    "    fig, axes = mpf.plot(\n",
    "        combined_df,\n",
    "        type='candle',\n",
    "        style=input_style,\n",
    "        volume=True,\n",
    "        mav=(20, 50),\n",
    "        returnfig=True,\n",
    "        title=title,\n",
    "        figsize=(12, 8),\n",
    "        show_nontrading=True\n",
    "    )\n",
    "    ax_main = axes[0]  # main price axis\n",
    "\n",
    "    # Determine the output candlestick color based on label\n",
    "    if label == 'long':\n",
    "        color_up = 'green'\n",
    "        color_down = 'green'\n",
    "    elif label == 'short':\n",
    "        color_up = 'red'\n",
    "        color_down = 'red'\n",
    "    else:  # 'flat'\n",
    "        color_up = 'blue'\n",
    "        color_down = 'blue'\n",
    "\n",
    "    # Create a market colors style for the output sequence\n",
    "    output_market_colors = mpf.make_marketcolors(\n",
    "        up=color_up,\n",
    "        down=color_down,\n",
    "        edge='inherit',\n",
    "        wick='inherit',\n",
    "        volume='inherit'\n",
    "    )\n",
    "    output_style = mpf.make_mpf_style(marketcolors=output_market_colors)\n",
    "\n",
    "    # Overlay the output sequence with its own style\n",
    "    mpf.plot(\n",
    "        output_df,\n",
    "        type='candle',\n",
    "        ax=ax_main,\n",
    "        style=output_style,\n",
    "        volume=False,\n",
    "        mav=(20, 50),\n",
    "        show_nontrading=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in random.sample(range(len(X_test_slice)), 100):\n",
    "    sample_idx = X_test_slice[idx]\n",
    "    print(\"expected/predicted: \", labels_test_slice[idx], predicted_labels[idx], \"correct: \", \"model\" if \\\n",
    "        compute_profit(np.expand_dims(X_test_slice[idx], axis=0), np.expand_dims(y_test_slice[idx], axis=0), np.expand_dims(predicted_labels[idx], axis=0))\\\n",
    "        >= \\\n",
    "        compute_profit(np.expand_dims(X_test_slice[idx], axis=0), np.expand_dims(y_test_slice[idx], axis=0), np.expand_dims(labels_test_slice[idx], axis=0))\\\n",
    "        else \"algo\"\n",
    "            )\n",
    "    # plot_input_output_combined_with_label(\n",
    "    #     X_test_slice[idx],\n",
    "    #     y_test_slice[idx],\n",
    "    #     label=predicted_labels[idx],\n",
    "    #     title=\"Input+Output, Colored by Label\"\n",
    "    # )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'simple1dcnn_state_dict.pth'\n",
    "required_columns = ['date', 'open', 'high', 'low', 'close', 'volume']\n",
    "# file_path = r\"C:\\GitCnn\\CnnTrading\\CnnTrans\\merged_output.csv\"\n",
    "file_path = r\"DataFromBinance.csv\"\n",
    "input_window = 150\n",
    "output_window = 15\n",
    "np.set_printoptions(formatter={'float_kind': lambda x: f'{x:.2f}'})\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Read & sort in descending order\n",
    "df = read_and_sort_csv(file_path, required_columns)[-30000:]\n",
    "\n",
    "# Assuming 'df' is your DataFrame with 'open', 'high', 'low', 'close', 'volume'\n",
    "\n",
    "# Moving Averages\n",
    "df['SMA_20'] = df['close'].rolling(window=20).mean()\n",
    "df['EMA_20'] = df['close'].ewm(span=20, adjust=False).mean()\n",
    "\n",
    "# RSI\n",
    "df['RSI_14'] = momentum.RSIIndicator(close=df['close'], window=14).rsi()\n",
    "\n",
    "# MACD\n",
    "macd = trend.MACD(close=df['close'])\n",
    "df['MACD'] = macd.macd()\n",
    "df['MACD_Signal'] = macd.macd_signal()\n",
    "df['MACD_Diff'] = macd.macd_diff()\n",
    "\n",
    "# Bollinger Bands\n",
    "bollinger = volatility.BollingerBands(close=df['close'], window=20, window_dev=2)\n",
    "df['Bollinger_High'] = bollinger.bollinger_hband()\n",
    "df['Bollinger_Low'] = bollinger.bollinger_lband()\n",
    "df['Bollinger_Middle'] = bollinger.bollinger_mavg()\n",
    "\n",
    "# ATR\n",
    "df['ATR_14'] = volatility.AverageTrueRange(high=df['high'], low=df['low'], close=df['close'], window=14).average_true_range()\n",
    "\n",
    "# OBV\n",
    "df['OBV'] = volume.OnBalanceVolumeIndicator(close=df['close'], volume=df['volume']).on_balance_volume()\n",
    "\n",
    "# Stochastic Oscillator\n",
    "stochastic = momentum.StochasticOscillator(high=df['high'], low=df['low'], close=df['close'], window=14, smooth_window=3)\n",
    "df['Stochastic_%K'] = stochastic.stoch()\n",
    "df['Stochastic_%D'] = stochastic.stoch_signal()\n",
    "\n",
    "# Ichimoku Cloud\n",
    "ichimoku = trend.IchimokuIndicator(high=df['high'], low=df['low'], window1=9, window2=26, window3=52)\n",
    "df['Ichimoku_A'] = ichimoku.ichimoku_a()\n",
    "df['Ichimoku_B'] = ichimoku.ichimoku_b()\n",
    "df['Ichimoku_Base_Line'] = ichimoku.ichimoku_base_line()\n",
    "df['Ichimoku_Conversion_Line'] = ichimoku.ichimoku_conversion_line()\n",
    "\n",
    "# Handle missing values\n",
    "df.dropna(inplace=True)  # or df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_sequences(df, input_window=input_window, output_window=output_window, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = compute_labels_simple(X, y, threshold = 0.15)\n",
    "print(f\"\\nCreated {X.shape[0]} input-output sequences.\")\n",
    "print(f\"Input shape: {X.shape}\")\n",
    "print(f\"Output shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the model architecture\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = HybridCNN(num_features=22, seq_len=150, num_classes=3)\n",
    "\n",
    "# Load the saved state dictionary\n",
    "model.load_state_dict(torch.load(r\"C:\\GitCnn\\CnnTraading\\CnnTrans\\HybridCNN_best_on_valid_state_dict.pth\", map_location=device))\n",
    "\n",
    "# Move to device\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do inference on a single sample from X_test\n",
    "predicted_labels = []\n",
    "model.eval()\n",
    "\n",
    "for X_single in X:\n",
    "    X_single_scaled = MinMaxScaler().fit_transform(X_single)  # shape (600,5)\n",
    "    X_single_scaled = np.expand_dims(X_single_scaled, axis=0)  # => (1,600,5)\n",
    "    X_single_transposed = np.transpose(X_single_scaled, (0, 2, 1))  # => (1,5,600)\n",
    "    X_single_tensor = torch.from_numpy(X_single_transposed).float().to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(X_single_tensor)   # => shape (1,3)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        predicted_label = predicted.item()  # 0,1,2\n",
    "\n",
    "    label_map = {0:\"short\",1:\"flat\",2:\"long\"}\n",
    "    predicted_labels.append(label_map[predicted_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kek = labels == predicted_labels\n",
    "unique, counts = np.unique(kek, return_counts=True)\n",
    "\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass, field\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr  # Import Pearson correlation function\n",
    "\n",
    "@dataclass\n",
    "class TradingStatisticDTO:\n",
    "    initial_capital: float\n",
    "    final_capital: float\n",
    "    total_profit: float\n",
    "    average_profit: float\n",
    "    return_on_investment: float\n",
    "    num_trades: int\n",
    "    long_trades: int\n",
    "    short_trades: int\n",
    "    flat_trades: int\n",
    "    position_size_per_trade: float  # Position size in dollars\n",
    "    \n",
    "    # Additional Metrics\n",
    "    win_trades: int\n",
    "    loss_trades: int\n",
    "    win_rate: float\n",
    "    loss_rate: float\n",
    "    average_win: float\n",
    "    average_loss: float\n",
    "    profit_factor: float\n",
    "    max_drawdown: float\n",
    "    max_consecutive_wins: int\n",
    "    max_consecutive_losses: int\n",
    "    max_win: float        # New Metric: Maximum single trade profit\n",
    "    max_loss: float       # New Metric: Maximum single trade loss\n",
    "    \n",
    "    # New Attribute: Capital History\n",
    "    capital_history: list = field(default_factory=list, repr=False)\n",
    "    \n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Converts the trading statistics into a Pandas DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing all trading statistics.\n",
    "        \"\"\"\n",
    "        data = {\n",
    "            'Initial Capital': [self.initial_capital],\n",
    "            'Final Capital': [self.final_capital],\n",
    "            'Total Profit': [self.total_profit],\n",
    "            'Average Profit': [self.average_profit],\n",
    "            'Return on Investment (ROI)': [self.return_on_investment],\n",
    "            'Number of Trades': [self.num_trades],\n",
    "            'Long Trades': [self.long_trades],\n",
    "            'Short Trades': [self.short_trades],\n",
    "            'Flat Trades': [self.flat_trades],\n",
    "            'Position Size per Trade': [self.position_size_per_trade],\n",
    "            'Winning Trades': [self.win_trades],\n",
    "            'Losing Trades': [self.loss_trades],\n",
    "            'Win Rate (%)': [self.win_rate],\n",
    "            'Loss Rate (%)': [self.loss_rate],\n",
    "            'Average Win': [self.average_win],\n",
    "            'Average Loss': [self.average_loss],\n",
    "            'Profit Factor': [self.profit_factor],\n",
    "            'Maximum Drawdown': [self.max_drawdown],\n",
    "            'Max Consecutive Wins': [self.max_consecutive_wins],\n",
    "            'Max Consecutive Losses': [self.max_consecutive_losses],\n",
    "            'Max Win': [self.max_win],\n",
    "            'Max Loss': [self.max_loss],\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "\n",
    "    def compare(self, other: 'TradingStatisticDTO', this_name: str, other_name: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Compares this TradingStatisticDTO with another instance and returns a DataFrame of differences.\n",
    "\n",
    "        Args:\n",
    "            other (TradingStatisticDTO): The other trading statistics to compare against.\n",
    "            this_name (str): Name/Identifier for the current instance.\n",
    "            other_name (str): Name/Identifier for the other instance.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing comparison of metrics between the two instances.\n",
    "        \"\"\"\n",
    "        metrics = {\n",
    "            'Final Capital': ('final_capital', 'higher is better'),\n",
    "            'Total Profit': ('total_profit', 'higher is better'),\n",
    "            'Average Profit': ('average_profit', 'higher is better'),\n",
    "            'Return on Investment (ROI)': ('return_on_investment', 'higher is better'),\n",
    "            'Number of Trades': ('num_trades', 'lower is better'),\n",
    "            'Long Trades': ('long_trades', 'no specific preference'),\n",
    "            'Short Trades': ('short_trades', 'no specific preference'),\n",
    "            'Win Trades': ('win_trades', 'higher is better'),\n",
    "            'Loss Trades': ('loss_trades', 'lower is better'),\n",
    "            'Win Rate (%)': ('win_rate', 'higher is better'),\n",
    "            'Loss Rate (%)': ('loss_rate', 'lower is better'),\n",
    "            'Average Win': ('average_win', 'higher is better'),\n",
    "            'Average Loss': ('average_loss', 'lower is better'),\n",
    "            'Profit Factor': ('profit_factor', 'higher is better'),\n",
    "            'Maximum Drawdown': ('max_drawdown', 'lower is better'),\n",
    "            'Max Consecutive Wins': ('max_consecutive_wins', 'higher is better'),\n",
    "            'Max Consecutive Losses': ('max_consecutive_losses', 'lower is better'),\n",
    "            'Max Win': ('max_win', 'higher is better'),\n",
    "            'Max Loss': ('max_loss', 'lower is better'),\n",
    "        }\n",
    "\n",
    "        comparison_results = []\n",
    "\n",
    "        for metric_name, (attribute, preference) in metrics.items():\n",
    "            self_value = getattr(self, attribute)\n",
    "            other_value = getattr(other, attribute)\n",
    "            difference = self_value - other_value\n",
    "\n",
    "            if preference == 'higher is better':\n",
    "                if difference > 0:\n",
    "                    status = 'Improved'\n",
    "                elif difference < 0:\n",
    "                    status = 'Declined'\n",
    "                else:\n",
    "                    status = 'Same'\n",
    "            elif preference == 'lower is better':\n",
    "                if difference < 0:\n",
    "                    status = 'Improved'\n",
    "                elif difference > 0:\n",
    "                    status = 'Declined'\n",
    "                else:\n",
    "                    status = 'Same'\n",
    "            else:\n",
    "                # For metrics where no specific preference is set\n",
    "                if difference > 0:\n",
    "                    status = 'Increased'\n",
    "                elif difference < 0:\n",
    "                    status = 'Decreased'\n",
    "                else:\n",
    "                    status = 'Same'\n",
    "\n",
    "            # Format the difference\n",
    "            if isinstance(self_value, float):\n",
    "                if 'Rate' in metric_name or 'Drawdown' in metric_name:\n",
    "                    # Format rates and drawdowns with appropriate units\n",
    "                    if 'Rate' in metric_name:\n",
    "                        diff_formatted = f\"{difference:+.2f}%\"\n",
    "                    elif 'Drawdown' in metric_name:\n",
    "                        diff_formatted = f\"${difference:+,.2f}\"\n",
    "                    else:\n",
    "                        diff_formatted = f\"${difference:+,.2f}\"\n",
    "                else:\n",
    "                    diff_formatted = f\"${difference:+,.2f}\"\n",
    "            else:\n",
    "                diff_formatted = f\"{difference:+}\"\n",
    "\n",
    "            # Prepare display values\n",
    "            if isinstance(other_value, float):\n",
    "                if 'Rate' in metric_name:\n",
    "                    other_display = f\"{other_value:.2f}%\"\n",
    "                elif 'Drawdown' in metric_name:\n",
    "                    other_display = f\"${other_value:,.2f}\"\n",
    "                else:\n",
    "                    other_display = f\"${other_value:,.2f}\"\n",
    "            else:\n",
    "                other_display = f\"{other_value}\"\n",
    "            \n",
    "            if isinstance(self_value, float):\n",
    "                if 'Rate' in metric_name:\n",
    "                    self_display = f\"{self_value:.2f}%\"\n",
    "                elif 'Drawdown' in metric_name:\n",
    "                    self_display = f\"${self_value:,.2f}\"\n",
    "                else:\n",
    "                    self_display = f\"${self_value:,.2f}\"\n",
    "            else:\n",
    "                self_display = f\"{self_value}\"\n",
    "\n",
    "            comparison_results.append({\n",
    "                'Metric': metric_name,\n",
    "                other_name: other_display,\n",
    "                this_name: self_display,\n",
    "                'Difference': diff_formatted,\n",
    "                'Status': status\n",
    "            })\n",
    "\n",
    "        comparison_df = pd.DataFrame(comparison_results)\n",
    "        return comparison_df\n",
    "\n",
    "    def plot_capital_history(self, title: str = \"Capital Over Time\"):\n",
    "        \"\"\"\n",
    "        Plots the capital history over time.\n",
    "\n",
    "        Args:\n",
    "            title (str, optional): The title of the plot. Defaults to \"Capital Over Time\".\n",
    "        \"\"\"\n",
    "        if not self.capital_history:\n",
    "            print(\"No capital history to plot.\")\n",
    "            return\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(self.capital_history, label='Capital', color='blue')\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Trade Number')\n",
    "        plt.ylabel('Capital ($)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    def correlation_with_linear_trend(self) -> float:\n",
    "        \"\"\"\n",
    "        Calculates the Pearson correlation coefficient between the actual capital history\n",
    "        and an ideal linear trend from initial to final capital.\n",
    "\n",
    "        Returns:\n",
    "            float: Pearson correlation coefficient. Returns np.nan if calculation is not possible.\n",
    "        \"\"\"\n",
    "        if not self.capital_history:\n",
    "            print(\"Capital history is empty.\")\n",
    "            return np.nan\n",
    "        if len(self.capital_history) < 2:\n",
    "            print(\"Not enough data points to calculate correlation.\")\n",
    "            return np.nan\n",
    "        \n",
    "        n = len(self.capital_history)\n",
    "        linear_trend = np.linspace(self.initial_capital, self.final_capital, n)\n",
    "        \n",
    "        # Calculate Pearson correlation\n",
    "        corr_coeff, _ = pearsonr(self.capital_history, linear_trend)\n",
    "        return corr_coeff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_trading_statistics(\n",
    "    X_benchmark: np.ndarray,\n",
    "    labels: list,\n",
    "    initial_capital: float,\n",
    "    position_size_dollars: float = 1000.0,  # Fixed position size per trade in dollars\n",
    "    close_idx: int = 3,\n",
    "    high_idx: int = 1,  # Index for High price\n",
    "    low_idx: int = 2,   # Index for Low price\n",
    "    commission_rate: float = 0.0005,\n",
    "    tp_percent: float = 0.01,  # 1% Take Profit\n",
    "    sl_percent: float = 0.005  # 0.5% Stop Loss\n",
    ") -> TradingStatisticDTO:\n",
    "    \"\"\"\n",
    "    Computes trading statistics based on initial capital, fixed dollar position size, and trade profits.\n",
    "    Positions are closed based on fixed Take Profit (TP) and Stop Loss (SL) percentages using High and Low prices.\n",
    "    Incorporates dynamic adjustment of SL and TP based on incoming labels.\n",
    "    \n",
    "    Args:\n",
    "        X_benchmark (np.ndarray): Input prices, shape (num_time_steps, num_features).\n",
    "        labels (list or np.ndarray): Trade labels for each time step (\"long\", \"short\", \"flat\").\n",
    "        initial_capital (float): The starting capital for trading.\n",
    "        position_size_dollars (float, optional): Fixed dollar amount per trade. Defaults to 1000.0.\n",
    "        close_idx (int, optional): Index of the closing price in the feature array. Defaults to 3.\n",
    "        high_idx (int, optional): Index of the high price in the feature array. Defaults to 2.\n",
    "        low_idx (int, optional): Index of the low price in the feature array. Defaults to 1.\n",
    "        commission_rate (float, optional): Commission rate per trade (as a decimal). Defaults to 0.0005.\n",
    "        tp_percent (float, optional): Take Profit percentage (e.g., 0.01 for 1%). Defaults to 0.01.\n",
    "        sl_percent (float, optional): Stop Loss percentage (e.g., 0.005 for 0.5%). Defaults to 0.005.\n",
    "\n",
    "    Returns:\n",
    "        TradingStatisticDTO: An object containing various trading statistics.\n",
    "    \"\"\"\n",
    "    # Parameter Validation (unchanged)\n",
    "    if initial_capital <= 0:\n",
    "        raise ValueError(\"Initial capital must be greater than zero.\")\n",
    "    if position_size_dollars <= 0:\n",
    "        raise ValueError(\"Position size must be greater than zero.\")\n",
    "    if not isinstance(labels, (list, np.ndarray)):\n",
    "        raise TypeError(\"Labels must be a list or numpy array.\")\n",
    "    if X_benchmark.shape[0] != len(labels):\n",
    "        raise ValueError(\"Number of time steps in X_benchmark must match the number of labels.\")\n",
    "\n",
    "    num_time_steps = X_benchmark.shape[0]\n",
    "    total_profit = 0.0\n",
    "    long_trades = 0\n",
    "    short_trades = 0\n",
    "    flat_trades = 0\n",
    "    num_trades = 0\n",
    "\n",
    "    # Additional Metrics Variables\n",
    "    win_trades = 0\n",
    "    loss_trades = 0\n",
    "    total_win = 0.0\n",
    "    total_loss = 0.0\n",
    "    trade_profits = []  # List to store individual trade profits for profit factor\n",
    "    current_capital = initial_capital\n",
    "    max_capital = initial_capital\n",
    "    max_drawdown = 0.0\n",
    "    consecutive_wins = 0\n",
    "    max_consecutive_wins = 0\n",
    "    consecutive_losses = 0\n",
    "    max_consecutive_losses = 0\n",
    "    max_win = float('-inf')  # Initialize to negative infinity\n",
    "    max_loss = float('inf')  # Initialize to infinity\n",
    "\n",
    "    # To track consecutive wins/losses\n",
    "    last_trade_result = None  # 'win' or 'loss'\n",
    "\n",
    "    current_position = 'flat'  # Possible values: 'flat', 'long', 'short'\n",
    "    entry_price = 0.0\n",
    "    tp_level = 0.0\n",
    "    sl_level = 0.0\n",
    "\n",
    "    # Initialize capital history\n",
    "    capital_history = [initial_capital]\n",
    "\n",
    "    for i in range(num_time_steps):\n",
    "        label = labels[i]\n",
    "        close_price = X_benchmark[i, close_idx]\n",
    "        high_price = X_benchmark[i, high_idx]\n",
    "        low_price = X_benchmark[i, low_idx]\n",
    "\n",
    "        if current_position == 'flat':\n",
    "            # Only consider opening a new position if flat\n",
    "            if label == \"long\":\n",
    "                # Open a long position at Close price\n",
    "                current_position = \"long\"\n",
    "                entry_price = close_price\n",
    "                long_trades += 1\n",
    "                num_trades += 1\n",
    "                # Calculate TP and SL levels based on entry price\n",
    "                tp_level = entry_price * (1 + tp_percent)\n",
    "                sl_level = entry_price * (1 - sl_percent)\n",
    "                # Commission on entry\n",
    "                # position_size_dollars = current_capital*0.3  # Adjusted position size as per original code\n",
    "                commission = commission_rate * position_size_dollars\n",
    "                total_profit -= commission\n",
    "                current_capital -= commission\n",
    "            elif label == \"short\":\n",
    "                # Open a short position at Close price\n",
    "                current_position = \"short\"\n",
    "                entry_price = close_price\n",
    "                short_trades += 1\n",
    "                num_trades += 1\n",
    "                # Calculate TP and SL levels based on entry price\n",
    "                tp_level = entry_price * (1 - tp_percent)\n",
    "                sl_level = entry_price * (1 + sl_percent)\n",
    "                # Commission on entry\n",
    "                # position_size_dollars = current_capital*0.3  # Adjusted position size as per original code\n",
    "                commission = commission_rate * position_size_dollars\n",
    "                total_profit -= commission\n",
    "                current_capital -= commission\n",
    "            else:\n",
    "                flat_trades += 1\n",
    "            # Record capital after deciding on position\n",
    "            capital_history.append(current_capital)\n",
    "        else:\n",
    "            # Currently in a position; check for dynamic adjustments and TP/SL hits\n",
    "            trade_closed = False\n",
    "            profit = 0.0\n",
    "\n",
    "            # **Dynamic Stop-Loss Adjustment on Reversal Labels**\n",
    "            if (label == \"long\" and current_position == \"short\") or (label == \"short\" and current_position == \"long\"):\n",
    "                if label == \"long\" and current_position == \"short\":\n",
    "                    # Potential reversal from short to long\n",
    "                    # Calculate new SL for the short position based on current price\n",
    "                    new_sl_level = close_price * (1 + sl_percent)\n",
    "                    # For short positions, SL is above the entry price\n",
    "                    # Only update SL if new SL is closer to current price than existing SL\n",
    "                    if new_sl_level < sl_level:\n",
    "                        sl_level = new_sl_level  # Update to closer SL\n",
    "                elif label == \"short\" and current_position == \"long\":\n",
    "                    # Potential reversal from long to short\n",
    "                    # Calculate new SL for the long position based on current price\n",
    "                    new_sl_level = close_price * (1 - sl_percent)\n",
    "                    # For long positions, SL is below the entry price\n",
    "                    # Only update SL if new SL is closer to current price than existing SL\n",
    "                    if new_sl_level > sl_level:\n",
    "                        sl_level = new_sl_level  # Update to closer SL\n",
    "\n",
    "            # **Dynamic Take-Profit Adjustment on Same Labels**\n",
    "            if label == current_position:\n",
    "                if current_position == \"long\":\n",
    "                    # Calculate new TP based on current price\n",
    "                    new_tp_level = close_price * (1 + tp_percent)\n",
    "                    # Update TP only if new TP is further from current price than existing TP\n",
    "                    if new_tp_level > tp_level:\n",
    "                        tp_level = new_tp_level\n",
    "                elif current_position == \"short\":\n",
    "                    # Calculate new TP based on current price\n",
    "                    new_tp_level = close_price * (1 - tp_percent)\n",
    "                    # Update TP only if new TP is further from current price than existing TP\n",
    "                    if new_tp_level < tp_level:\n",
    "                        tp_level = new_tp_level\n",
    "\n",
    "            # **Check for TP or SL Hits**\n",
    "            if current_position == \"long\":\n",
    "                # For long positions, TP is higher than entry, SL is lower\n",
    "                # Check TP first using High price\n",
    "                if high_price >= tp_level:\n",
    "                    # Take Profit at TP level\n",
    "                    exit_price = tp_level\n",
    "                    profit = (exit_price - entry_price) * (position_size_dollars / entry_price) - (commission_rate * position_size_dollars)\n",
    "                    trade_closed = True\n",
    "                # If TP not hit, check SL using Low price\n",
    "                elif low_price <= sl_level:\n",
    "                    # Stop Loss at SL level\n",
    "                    exit_price = sl_level\n",
    "                    profit = (exit_price - entry_price) * (position_size_dollars / entry_price) - (commission_rate * position_size_dollars)\n",
    "                    trade_closed = True\n",
    "            elif current_position == \"short\":\n",
    "                # For short positions, TP is lower than entry, SL is higher\n",
    "                # Check TP first using Low price\n",
    "                if low_price <= tp_level:\n",
    "                    # Take Profit at TP level\n",
    "                    exit_price = tp_level\n",
    "                    profit = (entry_price - exit_price) * (position_size_dollars / entry_price) - (commission_rate * position_size_dollars)\n",
    "                    trade_closed = True\n",
    "                # If TP not hit, check SL using High price\n",
    "                elif high_price >= sl_level:\n",
    "                    # Stop Loss at SL level\n",
    "                    exit_price = sl_level\n",
    "                    profit = (entry_price - exit_price) * (position_size_dollars / entry_price) - (commission_rate * position_size_dollars)\n",
    "                    trade_closed = True\n",
    "\n",
    "            if trade_closed:\n",
    "                total_profit += profit\n",
    "                current_capital += profit\n",
    "                trade_profits.append(profit)\n",
    "\n",
    "                # Update max win and max loss\n",
    "                if profit > max_win:\n",
    "                    max_win = profit\n",
    "                if profit < max_loss:\n",
    "                    max_loss = profit\n",
    "\n",
    "                # Update drawdown\n",
    "                if current_capital > max_capital:\n",
    "                    max_capital = current_capital\n",
    "                drawdown = max_capital - current_capital\n",
    "                if drawdown > max_drawdown:\n",
    "                    max_drawdown = drawdown\n",
    "\n",
    "                # Update win/loss statistics\n",
    "                if profit > 0:\n",
    "                    win_trades += 1\n",
    "                    total_win += profit\n",
    "                    if last_trade_result == 'win':\n",
    "                        consecutive_wins += 1\n",
    "                    else:\n",
    "                        consecutive_wins = 1\n",
    "                        consecutive_losses = 0\n",
    "                    last_trade_result = 'win'\n",
    "                    if consecutive_wins > max_consecutive_wins:\n",
    "                        max_consecutive_wins = consecutive_wins\n",
    "                elif profit < 0:\n",
    "                    loss_trades += 1\n",
    "                    total_loss += abs(profit)\n",
    "                    if last_trade_result == 'loss':\n",
    "                        consecutive_losses += 1\n",
    "                    else:\n",
    "                        consecutive_losses = 1\n",
    "                        consecutive_wins = 0\n",
    "                    last_trade_result = 'loss'\n",
    "                    if consecutive_losses > max_consecutive_losses:\n",
    "                        max_consecutive_losses = consecutive_losses\n",
    "                else:\n",
    "                    # Break-even trade; do not count as win or loss\n",
    "                    consecutive_wins = 0\n",
    "                    consecutive_losses = 0\n",
    "                    last_trade_result = None\n",
    "\n",
    "                # Reset position\n",
    "                current_position = \"flat\"\n",
    "\n",
    "                # Record capital after closing the trade\n",
    "                capital_history.append(current_capital)\n",
    "            else:\n",
    "                # Position remains open; record current capital without changes\n",
    "                capital_history.append(current_capital)\n",
    "\n",
    "    # After iterating through all time steps, check if a position is still open and close it\n",
    "    if current_position != \"flat\":\n",
    "        exit_price = X_benchmark[-1, close_idx]\n",
    "        if current_position == \"long\":\n",
    "            profit = (exit_price - entry_price) * (position_size_dollars / entry_price) - (commission_rate * position_size_dollars)\n",
    "        elif current_position == \"short\":\n",
    "            profit = (entry_price - exit_price) * (position_size_dollars / entry_price) - (commission_rate * position_size_dollars)\n",
    "        total_profit += profit\n",
    "        current_capital += profit\n",
    "        trade_profits.append(profit)\n",
    "\n",
    "        # Update max win and max loss\n",
    "        if profit > max_win:\n",
    "            max_win = profit\n",
    "        if profit < max_loss:\n",
    "            max_loss = profit\n",
    "\n",
    "        # Update drawdown\n",
    "        if current_capital > max_capital:\n",
    "            max_capital = current_capital\n",
    "        drawdown = max_capital - current_capital\n",
    "        if drawdown > max_drawdown:\n",
    "            max_drawdown = drawdown\n",
    "\n",
    "        # Update win/loss statistics\n",
    "        if profit > 0:\n",
    "            win_trades += 1\n",
    "            total_win += profit\n",
    "            if last_trade_result == 'win':\n",
    "                consecutive_wins += 1\n",
    "            else:\n",
    "                consecutive_wins = 1\n",
    "                consecutive_losses = 0\n",
    "            last_trade_result = 'win'\n",
    "            if consecutive_wins > max_consecutive_wins:\n",
    "                max_consecutive_wins = consecutive_wins\n",
    "        elif profit < 0:\n",
    "            loss_trades += 1\n",
    "            total_loss += abs(profit)\n",
    "            if last_trade_result == 'loss':\n",
    "                consecutive_losses += 1\n",
    "            else:\n",
    "                consecutive_losses = 1\n",
    "                consecutive_wins = 0\n",
    "            last_trade_result = 'loss'\n",
    "            if consecutive_losses > max_consecutive_losses:\n",
    "                max_consecutive_losses = consecutive_losses\n",
    "        else:\n",
    "            # Break-even trade; do not count as win or loss\n",
    "            consecutive_wins = 0\n",
    "            consecutive_losses = 0\n",
    "            last_trade_result = None\n",
    "\n",
    "        # Increment trade count for closing trade\n",
    "        if current_position == \"long\":\n",
    "            long_trades += 1\n",
    "        elif current_position == \"short\":\n",
    "            short_trades += 1\n",
    "        num_trades += 1  # Closing trade\n",
    "\n",
    "        # Record capital after closing the final trade\n",
    "        capital_history.append(current_capital)\n",
    "\n",
    "    # Calculate average profit\n",
    "    average_profit = total_profit / num_trades if num_trades > 0 else 0.0\n",
    "\n",
    "    # Calculate ROI\n",
    "    return_on_investment = (total_profit / initial_capital) * 100 if initial_capital != 0 else 0.0\n",
    "\n",
    "    # Calculate Win/Loss Rates\n",
    "    win_rate = (win_trades / num_trades) * 100 if num_trades > 0 else 0.0\n",
    "    loss_rate = (loss_trades / num_trades) * 100 if num_trades > 0 else 0.0\n",
    "\n",
    "    # Calculate Average Win and Average Loss\n",
    "    average_win = (total_win / win_trades) if win_trades > 0 else 0.0\n",
    "    average_loss = (total_loss / loss_trades) if loss_trades > 0 else 0.0\n",
    "\n",
    "    # Calculate Profit Factor\n",
    "    profit_factor = (total_win / total_loss) if total_loss > 0 else float('inf')\n",
    "\n",
    "    # Prepare the TradingStatisticDTO with all metrics\n",
    "    trading_stats = TradingStatisticDTO(\n",
    "        initial_capital=initial_capital,\n",
    "        final_capital=current_capital,\n",
    "        total_profit=total_profit,\n",
    "        average_profit=average_profit,\n",
    "        return_on_investment=return_on_investment,\n",
    "        num_trades=num_trades,\n",
    "        long_trades=long_trades,\n",
    "        short_trades=short_trades,\n",
    "        flat_trades=flat_trades,\n",
    "        position_size_per_trade=position_size_dollars,\n",
    "        win_trades=win_trades,\n",
    "        loss_trades=loss_trades,\n",
    "        win_rate=win_rate,\n",
    "        loss_rate=loss_rate,\n",
    "        average_win=average_win,\n",
    "        average_loss=average_loss,\n",
    "        profit_factor=profit_factor,\n",
    "        max_drawdown=max_drawdown,\n",
    "        max_consecutive_wins=max_consecutive_wins,\n",
    "        max_consecutive_losses=max_consecutive_losses,\n",
    "        max_win=max_win if max_win != float('-inf') else 0.0,    # Handle case with no wins\n",
    "        max_loss=max_loss if max_loss != float('inf') else 0.0,  # Handle case with no losses\n",
    "    )\n",
    "\n",
    "    # Assign the capital history\n",
    "    trading_stats.capital_history = capital_history\n",
    "\n",
    "    return trading_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingStatisticsCalculator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        initial_capital: float,\n",
    "        position_size_dollars: float = 1000.0,  # Fixed position size per trade in dollars\n",
    "        close_idx: int = 3,\n",
    "        high_idx: int = 1,  # Index for High price\n",
    "        low_idx: int = 2,   # Index for Low price\n",
    "        commission_rate: float = 0.0005,\n",
    "        tp_percent: float = 0.01,  # 1% Take Profit\n",
    "        sl_percent: float = 0.005  # 0.5% Stop Loss\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes the TradingStatisticsCalculator with the given parameters.\n",
    "\n",
    "        Args:\n",
    "            initial_capital (float): The starting capital for trading.\n",
    "            position_size_dollars (float, optional): Fixed dollar amount per trade. Defaults to 1000.0.\n",
    "            close_idx (int, optional): Index of the closing price in the feature array. Defaults to 3.\n",
    "            high_idx (int, optional): Index of the high price in the feature array. Defaults to 1.\n",
    "            low_idx (int, optional): Index of the low price in the feature array. Defaults to 2.\n",
    "            commission_rate (float, optional): Commission rate per trade (as a decimal). Defaults to 0.0005.\n",
    "            tp_percent (float, optional): Take Profit percentage (e.g., 0.01 for 1%). Defaults to 0.01.\n",
    "            sl_percent (float, optional): Stop Loss percentage (e.g., 0.005 for 0.5%). Defaults to 0.005.\n",
    "        \"\"\"\n",
    "        # Parameter Validation\n",
    "        if initial_capital <= 0:\n",
    "            raise ValueError(\"Initial capital must be greater than zero.\")\n",
    "        if position_size_dollars <= 0:\n",
    "            raise ValueError(\"Position size must be greater than zero.\")\n",
    "        \n",
    "        self.position_size_dollars = position_size_dollars\n",
    "        self.initial_capital = initial_capital\n",
    "        self.close_idx = close_idx\n",
    "        self.high_idx = high_idx\n",
    "        self.low_idx = low_idx\n",
    "        self.commission_rate = commission_rate\n",
    "        self.tp_percent = tp_percent\n",
    "        self.sl_percent = sl_percent\n",
    "        self.total_profit = 0.0\n",
    "        self.long_trades = 0\n",
    "        self.short_trades = 0\n",
    "        self.flat_trades = 0\n",
    "        self.num_trades = 0\n",
    "\n",
    "        # Additional Metrics Variables\n",
    "        self.win_trades = 0\n",
    "        self.loss_trades = 0\n",
    "        self.total_win = 0.0\n",
    "        self.total_loss = 0.0\n",
    "        self.trade_profits = []  # List to store individual trade profits for profit factor\n",
    "        self.current_capital = initial_capital\n",
    "        self.max_capital = initial_capital\n",
    "        self.max_drawdown = 0.0\n",
    "        self.consecutive_wins = 0\n",
    "        self.max_consecutive_wins = 0\n",
    "        self.consecutive_losses = 0\n",
    "        self.max_consecutive_losses = 0\n",
    "        self.max_win = float('-inf')  # Initialize to negative infinity\n",
    "        self.max_loss = float('inf')  # Initialize to infinity\n",
    "\n",
    "        # To track consecutive wins/losses\n",
    "        self.last_trade_result = None  # 'win' or 'loss'\n",
    "\n",
    "        self.current_position = 'flat'  # Possible values: 'flat', 'long', 'short'\n",
    "        self.entry_price = 0.0\n",
    "        self.tp_level = 0.0\n",
    "        self.sl_level = 0.0\n",
    "\n",
    "        # Initialize capital history\n",
    "        self.capital_history = [initial_capital]\n",
    "\n",
    "    def process_candle(self, candle: np.ndarray, label: str):\n",
    "        \"\"\"\n",
    "        Processes a single candle with the given label.\n",
    "\n",
    "        Args:\n",
    "            candle (np.ndarray): The candle data containing prices.\n",
    "            label (str): The trade label for the current time step (\"long\", \"short\", \"flat\").\n",
    "        \"\"\"\n",
    "        \n",
    "        close_price = candle[self.close_idx]\n",
    "        high_price = candle[self.high_idx]\n",
    "        low_price = candle[self.low_idx]\n",
    "\n",
    "        if self.current_position == 'flat':\n",
    "            # Only consider opening a new position if flat\n",
    "            if label == \"long\":\n",
    "                # Open a long position at Close price\n",
    "                self.current_position = \"long\"\n",
    "                self.entry_price = close_price\n",
    "                self.long_trades += 1\n",
    "                self.num_trades += 1\n",
    "                # Calculate TP and SL levels based on entry price\n",
    "                self.tp_level = self.entry_price * (1 + self.tp_percent)\n",
    "                self.sl_level = self.entry_price * (1 - self.sl_percent)\n",
    "                # Commission on entry\n",
    "                commission = self.commission_rate * self.position_size_dollars\n",
    "                self.total_profit -= commission\n",
    "                self.current_capital -= commission\n",
    "            elif label == \"short\":\n",
    "                # Open a short position at Close price\n",
    "                self.current_position = \"short\"\n",
    "                self.entry_price = close_price\n",
    "                self.short_trades += 1\n",
    "                self.num_trades += 1\n",
    "                # Calculate TP and SL levels based on entry price\n",
    "                self.tp_level = self.entry_price * (1 - self.tp_percent)\n",
    "                self.sl_level = self.entry_price * (1 + self.sl_percent)\n",
    "                # Commission on entry\n",
    "                commission = self.commission_rate * self.position_size_dollars\n",
    "                self.total_profit -= commission\n",
    "                self.current_capital -= commission\n",
    "            else:\n",
    "                self.flat_trades += 1\n",
    "            # Record capital after deciding on position\n",
    "            self.capital_history.append(self.current_capital)\n",
    "        else:\n",
    "            # Currently in a position; check for dynamic adjustments and TP/SL hits\n",
    "            trade_closed = False\n",
    "            profit = 0.0\n",
    "\n",
    "            # **Dynamic Stop-Loss Adjustment on Reversal Labels**\n",
    "            if (label == \"long\" and self.current_position == \"short\") or (label == \"short\" and self.current_position == \"long\"):\n",
    "                if label == \"long\" and self.current_position == \"short\":\n",
    "                    # Potential reversal from short to long\n",
    "                    # Calculate new SL for the short position based on current price\n",
    "                    new_sl_level = close_price * (1 + self.sl_percent)\n",
    "                    # For short positions, SL is above the entry price\n",
    "                    # Only update SL if new SL is closer to current price than existing SL\n",
    "                    if new_sl_level < self.sl_level:\n",
    "                        self.sl_level = new_sl_level  # Update to closer SL\n",
    "                elif label == \"short\" and self.current_position == \"long\":\n",
    "                    # Potential reversal from long to short\n",
    "                    # Calculate new SL for the long position based on current price\n",
    "                    new_sl_level = close_price * (1 - self.sl_percent)\n",
    "                    # For long positions, SL is below the entry price\n",
    "                    # Only update SL if new SL is closer to current price than existing SL\n",
    "                    if new_sl_level > self.sl_level:\n",
    "                        self.sl_level = new_sl_level  # Update to closer SL\n",
    "\n",
    "            # **Dynamic Take-Profit Adjustment on Same Labels**\n",
    "            if label == self.current_position:\n",
    "                if self.current_position == \"long\":\n",
    "                    # Calculate new TP based on current price\n",
    "                    new_tp_level = close_price * (1 + self.tp_percent)\n",
    "                    # Update TP only if new TP is further from current price than existing TP\n",
    "                    if new_tp_level > self.tp_level:\n",
    "                        self.tp_level = new_tp_level\n",
    "                elif self.current_position == \"short\":\n",
    "                    # Calculate new TP based on current price\n",
    "                    new_tp_level = close_price * (1 - self.tp_percent)\n",
    "                    # Update TP only if new TP is further from current price than existing TP\n",
    "                    if new_tp_level < self.tp_level:\n",
    "                        self.tp_level = new_tp_level\n",
    "\n",
    "            # **Check for TP or SL Hits**\n",
    "            if self.current_position == \"long\":\n",
    "                # For long positions, TP is higher than entry, SL is lower\n",
    "                # Check TP first using High price\n",
    "                if high_price >= self.tp_level:\n",
    "                    # Take Profit at TP level\n",
    "                    exit_price = self.tp_level\n",
    "                    profit = (exit_price - self.entry_price) * (self.position_size_dollars / self.entry_price) - (self.commission_rate * self.position_size_dollars)\n",
    "                    trade_closed = True\n",
    "                # If TP not hit, check SL using Low price\n",
    "                elif low_price <= self.sl_level:\n",
    "                    # Stop Loss at SL level\n",
    "                    exit_price = self.sl_level\n",
    "                    profit = (exit_price - self.entry_price) * (self.position_size_dollars / self.entry_price) - (self.commission_rate * self.position_size_dollars)\n",
    "                    trade_closed = True\n",
    "            elif self.current_position == \"short\":\n",
    "                # For short positions, TP is lower than entry, SL is higher\n",
    "                # Check TP first using Low price\n",
    "                if low_price <= self.tp_level:\n",
    "                    # Take Profit at TP level\n",
    "                    exit_price = self.tp_level\n",
    "                    profit = (self.entry_price - exit_price) * (self.position_size_dollars / self.entry_price) - (self.commission_rate * self.position_size_dollars)\n",
    "                    trade_closed = True\n",
    "                # If TP not hit, check SL using High price\n",
    "                elif high_price >= self.sl_level:\n",
    "                    # Stop Loss at SL level\n",
    "                    exit_price = self.sl_level\n",
    "                    profit = (self.entry_price - exit_price) * (self.position_size_dollars / self.entry_price) - (self.commission_rate * self.position_size_dollars)\n",
    "                    trade_closed = True\n",
    "\n",
    "            if trade_closed:\n",
    "                self.total_profit += profit\n",
    "                self.current_capital += profit\n",
    "                self.trade_profits.append(profit)\n",
    "\n",
    "                # Update max win and max loss\n",
    "                if profit > self.max_win:\n",
    "                    self.max_win = profit\n",
    "                if profit < self.max_loss:\n",
    "                    self.max_loss = profit\n",
    "\n",
    "                # Update drawdown\n",
    "                if self.current_capital > self.max_capital:\n",
    "                    self.max_capital = self.current_capital\n",
    "                drawdown = self.max_capital - self.current_capital\n",
    "                if drawdown > self.max_drawdown:\n",
    "                    self.max_drawdown = drawdown\n",
    "\n",
    "                # Update win/loss statistics\n",
    "                if profit > 0:\n",
    "                    self.win_trades += 1\n",
    "                    self.total_win += profit\n",
    "                    if self.last_trade_result == 'win':\n",
    "                        self.consecutive_wins += 1\n",
    "                    else:\n",
    "                        self.consecutive_wins = 1\n",
    "                        self.consecutive_losses = 0\n",
    "                    self.last_trade_result = 'win'\n",
    "                    if self.consecutive_wins > self.max_consecutive_wins:\n",
    "                        self.max_consecutive_wins = self.consecutive_wins\n",
    "                elif profit < 0:\n",
    "                    self.loss_trades += 1\n",
    "                    self.total_loss += abs(profit)\n",
    "                    if self.last_trade_result == 'loss':\n",
    "                        self.consecutive_losses += 1\n",
    "                    else:\n",
    "                        self.consecutive_losses = 1\n",
    "                        self.consecutive_wins = 0\n",
    "                    self.last_trade_result = 'loss'\n",
    "                    if self.consecutive_losses > self.max_consecutive_losses:\n",
    "                        self.max_consecutive_losses = self.consecutive_losses\n",
    "                else:\n",
    "                    # Break-even trade; do not count as win or loss\n",
    "                    self.consecutive_wins = 0\n",
    "                    self.consecutive_losses = 0\n",
    "                    self.last_trade_result = None\n",
    "\n",
    "                # Reset position\n",
    "                self.current_position = \"flat\"\n",
    "\n",
    "                # Record capital after closing the trade\n",
    "                self.capital_history.append(self.current_capital)\n",
    "            else:\n",
    "                # Position remains open; record current capital without changes\n",
    "                self.capital_history.append(self.current_capital)\n",
    "\n",
    "    def get_statistics(self) -> TradingStatisticDTO:\n",
    "        \"\"\"\n",
    "        Computes and returns the trading statistics.\n",
    "\n",
    "        Returns:\n",
    "            TradingStatisticDTO: An object containing various trading statistics.\n",
    "        \"\"\"\n",
    "        # Calculate average profit\n",
    "        average_profit = self.total_profit / self.num_trades if self.num_trades > 0 else 0.0\n",
    "\n",
    "        # Calculate ROI\n",
    "        return_on_investment = (self.total_profit / self.initial_capital) * 100 if self.initial_capital != 0 else 0.0\n",
    "\n",
    "        # Calculate Win/Loss Rates\n",
    "        win_rate = (self.win_trades / self.num_trades) * 100 if self.num_trades > 0 else 0.0\n",
    "        loss_rate = (self.loss_trades / self.num_trades) * 100 if self.num_trades > 0 else 0.0\n",
    "\n",
    "        # Calculate Average Win and Average Loss\n",
    "        average_win = (self.total_win / self.win_trades) if self.win_trades > 0 else 0.0\n",
    "        average_loss = (self.total_loss / self.loss_trades) if self.loss_trades > 0 else 0.0\n",
    "\n",
    "        # Calculate Profit Factor\n",
    "        profit_factor = (self.total_win / self.total_loss) if self.total_loss > 0 else float('inf')\n",
    "\n",
    "        # Handle cases where max_win and max_loss were never updated\n",
    "        final_max_win = self.max_win if self.max_win != float('-inf') else 0.0\n",
    "        final_max_loss = self.max_loss if self.max_loss != float('inf') else 0.0\n",
    "\n",
    "        # Prepare the TradingStatisticDTO with all metrics\n",
    "        trading_stats = TradingStatisticDTO(\n",
    "            initial_capital=self.initial_capital,\n",
    "            final_capital=self.current_capital,\n",
    "            total_profit=self.total_profit,\n",
    "            average_profit=average_profit,\n",
    "            return_on_investment=return_on_investment,\n",
    "            num_trades=self.num_trades,\n",
    "            long_trades=self.long_trades,\n",
    "            short_trades=self.short_trades,\n",
    "            flat_trades=self.flat_trades,\n",
    "            position_size_per_trade=self.position_size_dollars,\n",
    "            win_trades=self.win_trades,\n",
    "            loss_trades=self.loss_trades,\n",
    "            win_rate=win_rate,\n",
    "            loss_rate=loss_rate,\n",
    "            average_win=average_win,\n",
    "            average_loss=average_loss,\n",
    "            profit_factor=profit_factor,\n",
    "            max_drawdown=self.max_drawdown,\n",
    "            max_consecutive_wins=self.max_consecutive_wins,\n",
    "            max_consecutive_losses=self.max_consecutive_losses,\n",
    "            max_win=final_max_win,\n",
    "            max_loss=final_max_loss,\n",
    "            capital_history=self.capital_history.copy(),\n",
    "        )\n",
    "\n",
    "        return trading_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the last time step for each sample\n",
    "X_benchmark = X[:, -1, :]  # Shape: (9803, 22)\n",
    "\n",
    "# Verify the shapes\n",
    "print(\"Original X shape:\", X.shape)           # Output: (9803, 150, 22)\n",
    "print(\"X_benchmark shape:\", X_benchmark.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_benchmark[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_trading_statistics(X_benchmark, labels,1000, 500).to_dataframe().T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_trading_statistics(X_benchmark, predicted_labels,1000, 500).to_dataframe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import plotly\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial, X_benchmark, labels, initial_capital):\n",
    "    # Define the search space for TP and SL\n",
    "    tp_percent = trial.suggest_float('tp_percent', 0.0001, 0.05)  # 0.5% to 5%\n",
    "    sl_percent = trial.suggest_float('sl_percent', 0.0001, 0.02)  # 0.1% to 2%\n",
    "    \n",
    "    # Constraint: TP should be greater than SL\n",
    "    if tp_percent <= sl_percent:\n",
    "        return -np.inf  # Penalize invalid configurations\n",
    "    \n",
    "    # Compute trading statistics with the suggested TP and SL\n",
    "    stats = compute_trading_statistics(\n",
    "        X_benchmark=X_benchmark,\n",
    "        labels=labels,\n",
    "        initial_capital=initial_capital,\n",
    "        position_size_dollars=500.0,  # Can also be a hyperparameter\n",
    "        close_idx=3,\n",
    "        commission_rate=0.0005,\n",
    "        tp_percent=tp_percent,\n",
    "        sl_percent=sl_percent\n",
    "    )\n",
    "    \n",
    "    # Choose the metric to maximize\n",
    "    roi = stats.return_on_investment\n",
    "    \n",
    "    return roi  # Optuna will maximize this by default\n",
    "\n",
    "# Define a function to optimize TP and SL using Optuna\n",
    "def optimize_tp_sl(X_benchmark, labels, initial_capital, n_trials=300):\n",
    "    \"\"\"\n",
    "    Optimizes TP and SL percentages using Optuna.\n",
    "    \n",
    "    Args:\n",
    "        X_benchmark (np.ndarray): Input prices, shape (num_time_steps, num_features).\n",
    "        labels (list or np.ndarray): Trade labels for each time step (\"long\", \"short\", \"flat\").\n",
    "        initial_capital (float): The starting capital for trading.\n",
    "        n_trials (int): Number of Optuna trials.\n",
    "    \n",
    "    Returns:\n",
    "        study: The Optuna study object after optimization.\n",
    "    \"\"\"\n",
    "    # Define a partial objective function with fixed data\n",
    "    def objective_wrapper(trial):\n",
    "        return objective(trial, X_benchmark, labels, initial_capital)\n",
    "    \n",
    "    # Create the study\n",
    "    study = optuna.create_study(direction='maximize', study_name='TP_SL_Optimization')\n",
    "    \n",
    "    # Optimize\n",
    "    study.optimize(objective_wrapper, n_trials=n_trials)\n",
    "    \n",
    "    return study\n",
    "\n",
    "initial_capital = 1000\n",
    "study = optimize_tp_sl(\n",
    "    X_benchmark=X_benchmark,\n",
    "    labels=labels,\n",
    "    initial_capital=initial_capital,\n",
    "    n_trials=600  # Adjust based on computational resources\n",
    ")\n",
    "\n",
    "# Print the best parameters and ROI\n",
    "best_params = study.best_params\n",
    "best_roi = study.best_value\n",
    "\n",
    "print(f\"Best TP Percentage: {best_params['tp_percent']*100:.2f}%\")\n",
    "print(f\"Best SL Percentage: {best_params['sl_percent']*100:.2f}%\")\n",
    "print(f\"Best ROI: {best_roi:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_capital = 1000\n",
    "study = optimize_tp_sl(\n",
    "    X_benchmark=X_benchmark,\n",
    "    labels=predicted_labels,\n",
    "    initial_capital=initial_capital,\n",
    "    n_trials=600  # Adjust based on computational resources\n",
    ")\n",
    "\n",
    "# Print the best parameters and ROI\n",
    "best_params = study.best_params\n",
    "best_roi = study.best_value\n",
    "\n",
    "print(f\"Best TP Percentage: {best_params['tp_percent']*100:.2f}%\")\n",
    "print(f\"Best SL Percentage: {best_params['sl_percent']*100:.2f}%\")\n",
    "print(f\"Best ROI: {best_roi:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_benchmark[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_calc = TradingStatisticsCalculator(\n",
    "    initial_capital=5000.0,  # Example initial capital\n",
    "    position_size_dollars=1000.0,  # Example position size\n",
    "    close_idx=3,\n",
    "    high_idx=1,\n",
    "    low_idx=2,\n",
    "    commission_rate=0.0005,\n",
    "    tp_percent=0.0034,\n",
    "    sl_percent=0.0033\n",
    ")\n",
    "for candle, label in zip(X_benchmark, labels):\n",
    "    algo_calc.process_candle(candle, label)\n",
    "algo_stats = algo_calc.get_statistics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_calc = TradingStatisticsCalculator(\n",
    "    initial_capital=5000.0,  # Example initial capital\n",
    "    position_size_dollars=1000.0,  # Example position size\n",
    "    close_idx=3,\n",
    "    high_idx=1,\n",
    "    low_idx=2,\n",
    "    commission_rate=0.0005,\n",
    "    tp_percent=0.0034,\n",
    "    sl_percent=0.0033\n",
    ")\n",
    "for candle, label in zip(X_benchmark, predicted_labels):\n",
    "    model_calc.process_candle(candle, label)\n",
    "model_stats = model_calc.get_statistics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algo_stats = compute_trading_statistics(X_benchmark, labels,1000, 500, tp_percent=0.0155, sl_percent= 0.0045, commission_rate=0.0005)\n",
    "# algo_stats = compute_trading_statistics(X_benchmark, labels,5000, 5000, tp_percent=0.0034, sl_percent= 0.0033, commission_rate=0.0005)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_stats =compute_trading_statistics(X_benchmark, predicted_labels,1000, 500, tp_percent=0.0155, sl_percent= 0.0045, commission_rate=0.0005)\n",
    "# model_stats =compute_trading_statistics(X_benchmark, predicted_labels,5000, 5000, tp_percent=0.0034, sl_percent= 0.0033, commission_rate=0.0005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats.compare(algo_stats, \"Model\", \"Algo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_stats.plot_capital_history()\n",
    "model_stats.plot_capital_history()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_stats.correlation_with_linear_trend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats.correlation_with_linear_trend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from binance.client import Client\n",
    "# import pandas as pd\n",
    "# import datetime\n",
    "\n",
    "# # Binance API credentials\n",
    "# client = Client(api_key, api_secret)\n",
    "\n",
    "# # Define the symbol for BTC/USDT pair\n",
    "# symbol = 'BTCUSDT'\n",
    "\n",
    "# # Define custom start and end time\n",
    "# start_time = datetime.datetime(2024, 12, 26, 0, 0, 0)\n",
    "# end_time = datetime.datetime(2024, 12, 30, 0, 0, 0)\n",
    "\n",
    "# klines = client.get_historical_klines(symbol=symbol, interval=Client.KLINE_INTERVAL_1MINUTE, start_str=str(start_time), end_str=str(end_time))\n",
    "\n",
    "# # Convert the data into a pandas dataframe for easier manipulation\n",
    "# df_M = pd.DataFrame(klines, columns=['Open Time', 'Open', 'High', 'Low', 'Close', 'Volume', 'Close Time', 'Quote Asset Volume', 'Number of Trades', 'Taker Buy Base Asset Volume', 'Taker Buy Quote Asset Volume', 'Ignore'])\n",
    "\n",
    "\n",
    "# columns_to_convert = ['Open', 'High', 'Low', 'Close', 'Volume', 'Quote Asset Volume', 'Number of Trades', 'Taker Buy Base Asset Volume', 'Taker Buy Quote Asset Volume']\n",
    "\n",
    "# for col in columns_to_convert:\n",
    "#     df_M[col] = df_M[col].astype(float)\n",
    "# df_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_M.to_csv('DataFromBinance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv('DataFromBinance.csv').info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Convert 'Open Time' from Unix timestamp to datetime\n",
    "# df_M['date'] = pd.to_datetime(df_M['Open Time'], unit='ms')\n",
    "\n",
    "# # Select the desired columns\n",
    "# df_formatted = df_M[['date', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "\n",
    "# # Rename columns to lowercase\n",
    "# df_formatted.rename(columns={\n",
    "#     'Open': 'open',\n",
    "#     'High': 'high',\n",
    "#     'Low': 'low',\n",
    "#     'Close': 'close',\n",
    "#     'Volume': 'volume'\n",
    "# }, inplace=True)\n",
    "\n",
    "# # Rearrange columns if necessary\n",
    "# df_formatted = df_formatted[['date', 'open', 'high', 'low', 'close', 'volume']]\n",
    "# # Display the formatted DataFrame\n",
    "# df_formatted.set_index('date', inplace=True)\n",
    "\n",
    "# df_formatted.to_csv('DataFromBinance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
